{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook can only run at the same level as `src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load default config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the config data the package take to build graph/model and do train/inference, can be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET:\n",
      "  DATA_PATH: /home/NOBACKUP/mzhou3/599/ns_music_all_data.p\n",
      "  INTERACTION_DF: df_playlist\n",
      "  ITEM: track\n",
      "  ITEM_DF: df_track\n",
      "  ITEM_FEATURES: [['key', 'CAT'], ['tempo_5cat', 'CAT'], ['livness_5cat', 'CAT'], ['instrumentalness_3cat', 'CAT'], ['speechiness_10cat', 'CAT'], ['loudness_10cat', 'CAT'], ['acousticness_10cat', 'CAT'], ['artist_id', 'CAT'], ['album_id', 'CAT'], ['music_continous_features', 'VEC'], ['genre_old_vec', 'VEC'], ['genres_vec', 'VEC']]\n",
      "  ITEM_ID: tid\n",
      "  ITEM_USER_EDGE: contained_by\n",
      "  NAME: SPOTIFY_MUSIC\n",
      "  SAMPLER:\n",
      "    NEIGHBOR_SAMPLER:\n",
      "      DEFAULT_SAMPLER:\n",
      "        NUM_LAYERS: 2\n",
      "        NUM_NEIGHBORS: 3\n",
      "        NUM_RANDOM_WALKS: 10\n",
      "        RANDOM_WALK_LENGTH: 2\n",
      "        RANDOM_WALK_RESTART_PROB: 0.5\n",
      "      NAME: DEFAULT\n",
      "    NODES_SAMPLER:\n",
      "      BATCH_SIZE: 32\n",
      "      NAME: DEFAULT\n",
      "      PATH: \n",
      "  USER: playlist\n",
      "  USER_DF: df_playlist_info\n",
      "  USER_ID: pid\n",
      "  USER_ITEM_EDGE: contains\n",
      "FP16: False\n",
      "MODEL:\n",
      "  ARCH: PINSAGE\n",
      "  PINSAGE:\n",
      "    HIDDEN_SIZE: 128\n",
      "    LAYERS: 2\n",
      "    PROJECTION:\n",
      "      ADD: ['id', 'artist_id', 'album_id']\n",
      "      CONCAT: ['key', 'tempo_5cat', 'livness_5cat', 'instrumentalness_3cat', 'speechiness_10cat', 'loudness_10cat', 'acousticness_10cat', 'music_continous_features', 'genre_old_vec', 'genres_vec']\n",
      "      EMB: [['id', 128], ['album_id', 128], ['artist_id', 128], ['key', 16], ['tempo_5cat', 8], ['livness_5cat', 8], ['instrumentalness_3cat', 4], ['speechiness_10cat', 16], ['loudness_10cat', 16], ['acousticness_10cat', 16]]\n",
      "      FEATURES: ['key', 'tempo_5cat', 'livness_5cat', 'instrumentalness_3cat', 'speechiness_10cat', 'loudness_10cat', 'acousticness_10cat', 'artist_id', 'album_id', 'music_continous_features', 'genre_old_vec', 'genres_vec', 'id']\n",
      "      NORMALIZE: False\n",
      "    REPRESENTATION_NORMALIZE: False\n",
      "    SCORER: DEFAULT\n",
      "    SCORER_BIAS: False\n",
      "OUTPUT_PATH: \n",
      "TRAIN:\n",
      "  BATCHES_PER_EPOCH: 50000\n",
      "  ENABLE: True\n",
      "  EPOCHS: 10\n",
      "  LOSS: RAW_MARGIN_LOSS\n",
      "  SOLVER:\n",
      "    BASE_LR: 3e-05\n",
      "    OPTIMIZING_METHOD: adam\n",
      "    SGD:\n",
      "      DAMPENING: 0.0\n",
      "      MOMENTUM: 0.9\n",
      "      NESTEROV: True\n",
      "    STEP_LRS: [[0, 0.01], [1, 0.001], [2, 0.0001], [3, 3e-05]]\n",
      "    WEIGHT_DECAY: 0\n"
     ]
    }
   ],
   "source": [
    "from src.configs.defaults import get_cfg_defaults\n",
    "cfg = get_cfg_defaults()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data path \n",
    "cfg_data = cfg.DATASET\n",
    "cfg_data.DATA_PATH = 'ns_music_all_data_ming_20211124'\n",
    "# specify output path\n",
    "cfg.OUTPUT_PATH = '/home/NOBACKUP/mzhou3/599/test_run_8'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model changes\n",
    "- use layer norm at projection and representation\n",
    "- change representation embedding size to be 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.PINSAGE.PROJECTION.NORMALIZE= True\n",
    "cfg.MODEL.PINSAGE.REPRESENTATION_NORMALIZE= True\n",
    "cfg.MODEL.PINSAGE.HIDDEN_SIZE = 64\n",
    "cfg.MODEL.PINSAGE.PROJECTION.EMB = [['id', 64],\n",
    " ['album_id', 64],\n",
    " ['artist_id', 64],\n",
    " ['key', 16],\n",
    " ['tempo_5cat', 8],\n",
    " ['livness_5cat', 8],\n",
    " ['instrumentalness_3cat', 4],\n",
    " ['speechiness_10cat', 16],\n",
    " ['loudness_10cat', 16],\n",
    " ['acousticness_10cat', 16]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import build_model\n",
    "from src.data.dataset import build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, train_g, [train_user_ids, val_user_ids, test_user_ids] = build_dataset(cfg)\n",
    "model = build_model(g, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "model_state = torch.load('weights_fullmodel_size64_epoch5.p', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state['model_state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from src.data.sampler.graph_sampler import build_graph_sampler\n",
    "\n",
    "\n",
    "neighbor_sampler, collator = build_graph_sampler(train_g, cfg)\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "        torch.arange(g.number_of_nodes('track')),\n",
    "        batch_size=32,\n",
    "        collate_fn=collator.collate_test,\n",
    "        num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "model = model.cuda()\n",
    "device = torch.device('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_features_cpu = []\n",
    "dataloader_it = iter(dataloader_test)\n",
    "idx =0 \n",
    "for blocks in dataloader_it:\n",
    "    idx +=1 \n",
    "    if idx % 100 ==0:\n",
    "        print(idx)\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(blocks)):\n",
    "            blocks[i] = blocks[i].to(device)\n",
    "\n",
    "        features = model.get_repr(blocks)\n",
    "        all_features_cpu.append(features.cpu().numpy())\n",
    "all_features_cpu = np.concatenate(all_features_cpu)\n",
    "\n",
    "# save\n",
    "#import pickle\n",
    "#pickle.dump(all_features_cpu, open('embs', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ming_env] *",
   "language": "python",
   "name": "conda-env-ming_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
