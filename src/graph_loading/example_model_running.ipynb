{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os \n",
    "import dgl\n",
    "import pickle\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype, is_categorical\n",
    "import torch\n",
    "import pandas as pd \n",
    "import dgl.function as fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_music_all_data = pickle.load(open('ns_music_all_data.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlists = ns_music_all_data['df_playlist']\n",
    "df_playlists_info = ns_music_all_data['df_playlist_info']\n",
    "df_tracks = ns_music_all_data['df_track']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build Playlist-Track graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _series_to_tensor(series):\n",
    "    if is_categorical(series):\n",
    "        return torch.LongTensor(series.cat.codes.values.astype('int64'))\n",
    "    else:       # numeric\n",
    "        return torch.FloatTensor(series.values)\n",
    "\n",
    "class PandasGraphBuilder(object):\n",
    "    \"\"\"Creates a heterogeneous graph from multiple pandas dataframes.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Let's say we have the following three pandas dataframes:\n",
    "\n",
    "    User table ``users``:\n",
    "\n",
    "    ===========  ===========  =======\n",
    "    ``user_id``  ``country``  ``age``\n",
    "    ===========  ===========  =======\n",
    "    XYZZY        U.S.         25\n",
    "    FOO          China        24\n",
    "    BAR          China        23\n",
    "    ===========  ===========  =======\n",
    "\n",
    "    Game table ``games``:\n",
    "\n",
    "    ===========  =========  ==============  ==================\n",
    "    ``game_id``  ``title``  ``is_sandbox``  ``is_multiplayer``\n",
    "    ===========  =========  ==============  ==================\n",
    "    1            Minecraft  True            True\n",
    "    2            Tetris 99  False           True\n",
    "    ===========  =========  ==============  ==================\n",
    "\n",
    "    Play relationship table ``plays``:\n",
    "\n",
    "    ===========  ===========  =========\n",
    "    ``user_id``  ``game_id``  ``hours``\n",
    "    ===========  ===========  =========\n",
    "    XYZZY        1            24\n",
    "    FOO          1            20\n",
    "    FOO          2            16\n",
    "    BAR          2            28\n",
    "    ===========  ===========  =========\n",
    "\n",
    "    One could then create a bidirectional bipartite graph as follows:\n",
    "    >>> builder = PandasGraphBuilder()\n",
    "    >>> builder.add_entities(users, 'user_id', 'user')\n",
    "    >>> builder.add_entities(games, 'game_id', 'game')\n",
    "    >>> builder.add_binary_relations(plays, 'user_id', 'game_id', 'plays')\n",
    "    >>> builder.add_binary_relations(plays, 'game_id', 'user_id', 'played-by')\n",
    "    >>> g = builder.build()\n",
    "    >>> g.number_of_nodes('user')\n",
    "    3\n",
    "    >>> g.number_of_edges('plays')\n",
    "    4\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.entity_tables = {}\n",
    "        self.relation_tables = {}\n",
    "\n",
    "        self.entity_pk_to_name = {}     # mapping from primary key name to entity name\n",
    "        self.entity_pk = {}             # mapping from entity name to primary key\n",
    "        self.entity_key_map = {}        # mapping from entity names to primary key values\n",
    "        self.num_nodes_per_type = {}\n",
    "        self.edges_per_relation = {}\n",
    "        self.relation_name_to_etype = {}\n",
    "        self.relation_src_key = {}      # mapping from relation name to source key\n",
    "        self.relation_dst_key = {}      # mapping from relation name to destination key\n",
    "\n",
    "    def add_entities(self, entity_table, primary_key, name):\n",
    "        entities = entity_table[primary_key].astype('category')\n",
    "        if not (entities.value_counts() == 1).all():\n",
    "            raise ValueError('Different entity with the same primary key detected.')\n",
    "        # preserve the category order in the original entity table\n",
    "        entities = entities.cat.reorder_categories(entity_table[primary_key].values)\n",
    "\n",
    "        self.entity_pk_to_name[primary_key] = name\n",
    "        self.entity_pk[name] = primary_key\n",
    "        self.num_nodes_per_type[name] = entity_table.shape[0]\n",
    "        self.entity_key_map[name] = entities\n",
    "        self.entity_tables[name] = entity_table\n",
    "\n",
    "    def add_binary_relations(self, relation_table, source_key, destination_key, name):\n",
    "        src = relation_table[source_key].astype('category')\n",
    "        src = src.cat.set_categories(\n",
    "            self.entity_key_map[self.entity_pk_to_name[source_key]].cat.categories)\n",
    "        dst = relation_table[destination_key].astype('category')\n",
    "        dst = dst.cat.set_categories(\n",
    "            self.entity_key_map[self.entity_pk_to_name[destination_key]].cat.categories)\n",
    "        if src.isnull().any():\n",
    "            raise ValueError(\n",
    "                'Some source entities in relation %s do not exist in entity %s.' %\n",
    "                (name, source_key))\n",
    "        if dst.isnull().any():\n",
    "            raise ValueError(\n",
    "                'Some destination entities in relation %s do not exist in entity %s.' %\n",
    "                (name, destination_key))\n",
    "\n",
    "        srctype = self.entity_pk_to_name[source_key]\n",
    "        dsttype = self.entity_pk_to_name[destination_key]\n",
    "        etype = (srctype, name, dsttype)\n",
    "        self.relation_name_to_etype[name] = etype\n",
    "        self.edges_per_relation[etype] = (src.cat.codes.values.astype('int64'), dst.cat.codes.values.astype('int64'))\n",
    "        self.relation_tables[name] = relation_table\n",
    "        self.relation_src_key[name] = source_key\n",
    "        self.relation_dst_key[name] = destination_key\n",
    "\n",
    "    def build(self):\n",
    "        # Create heterograph\n",
    "        graph = dgl.heterograph(self.edges_per_relation, self.num_nodes_per_type)\n",
    "        return graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build bipartite heterogenous graph:\n",
    "\n",
    "- track is identified by tid\n",
    "- playlist is identified by pid \n",
    "- edge contains : play list contains track \n",
    "- edge contained_by: track is contained by playlist\n",
    "\n",
    "\n",
    "ids of nodes in graph and rows in dataset are in the same order:\n",
    "- 1st track node is track with tid =1 \n",
    "- 1st playlist node is play list with pid = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = PandasGraphBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlists_info = df_playlists_info.sort_values('pid').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = PandasGraphBuilder()\n",
    "graph_builder.add_entities(df_tracks, 'tid', 'track')\n",
    "graph_builder.add_entities(df_playlists_info, 'pid', 'playlist')\n",
    "graph_builder.add_binary_relations(df_playlists, 'pid', 'tid', 'contains')\n",
    "graph_builder.add_binary_relations(df_playlists, 'tid', 'pid', 'contained_by')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graph_builder.build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features to graph\n",
    "- music features are stored as long tensors (categorical, to be embedded)\n",
    "- genre, album_img_emb, album_text_emb are stored as numerical features \n",
    "- track id, play list id are also included, can be embedded as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']:\n",
    "    \n",
    "    g.nodes['track'].data[key] = torch.LongTensor(df_tracks[key].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['track'].data['genre'] = torch.tensor(np.asarray(list(df_tracks['genre'].values))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['track'].data['album_img_emb'] = torch.tensor(np.asarray(list(df_tracks['album_img_emb'].values)))\n",
    "g.nodes['track'].data['album_text_emb'] = torch.tensor(np.asarray(list(df_tracks['album_text_emb'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['playlist'].data['id'] = torch.arange(g.number_of_nodes('playlist'))\n",
    "g.nodes['track'].data['id'] = torch.arange(g.number_of_nodes('track'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeSpace(data={'id': tensor([     0,      1,      2,  ..., 999997, 999998, 999999])})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes['playlist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeSpace(data={'danceability': tensor([3, 3, 3,  ..., 3, 2, 1]), 'energy': tensor([3, 3, 3,  ..., 2, 3, 2]), 'loudness': tensor([2, 3, 2,  ..., 2, 2, 2]), 'speechiness': tensor([3, 3, 3,  ..., 2, 1, 1]), 'acousticness': tensor([1, 1, 1,  ..., 1, 1, 2]), 'instrumentalness': tensor([2, 2, 1,  ..., 2, 1, 2]), 'liveness': tensor([1, 3, 1,  ..., 2, 2, 2]), 'valence': tensor([3, 3, 3,  ..., 2, 3, 1]), 'tempo': tensor([2, 3, 1,  ..., 1, 3, 2]), 'genre': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'album_img_emb': tensor([[0.2030, 1.0508, 1.4206,  ..., 0.1448, 0.7110, 0.6996],\n",
       "        [0.1082, 2.7684, 1.0451,  ..., 0.1598, 0.2774, 0.0799],\n",
       "        [0.1201, 0.2322, 1.0679,  ..., 0.0352, 0.0731, 0.4070],\n",
       "        ...,\n",
       "        [1.2159, 2.7029, 1.2146,  ..., 0.0867, 0.0533, 0.6647],\n",
       "        [1.2159, 2.7029, 1.2146,  ..., 0.0867, 0.0533, 0.6647],\n",
       "        [0.2218, 2.4422, 0.2123,  ..., 0.1531, 0.1810, 0.2854]]), 'album_text_emb': tensor([[-0.0253,  0.0434, -0.0066,  ...,  0.0283, -0.0061,  0.0462],\n",
       "        [-0.0212,  0.0057, -0.0284,  ...,  0.0191, -0.0024,  0.0392],\n",
       "        [ 0.0151, -0.0277, -0.0044,  ..., -0.0733, -0.0219, -0.0009],\n",
       "        ...,\n",
       "        [ 0.0458, -0.0155, -0.0424,  ..., -0.0100,  0.0348, -0.0266],\n",
       "        [ 0.0458, -0.0155, -0.0424,  ..., -0.0100,  0.0348, -0.0266],\n",
       "        [ 0.0354, -0.0374, -0.0314,  ...,  0.0333, -0.0125,  0.0305]]), 'id': tensor([      0,       1,       2,  ..., 2262187, 2262188, 2262189])})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes['track']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS PART IS MISSING, FOR NOW EVERY ENTRY IS IN TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_graph(g, train_indices, utype, itype, etype, etype_rev):\n",
    "    train_g = g.edge_subgraph(\n",
    "        {etype: train_indices, etype_rev: train_indices},\n",
    "        relabel_nodes=False)\n",
    "\n",
    "    # copy features\n",
    "    for ntype in g.ntypes:\n",
    "        for col, data in g.nodes[ntype].data.items():\n",
    "            train_g.nodes[ntype].data[col] = data\n",
    "    for etype in g.etypes:\n",
    "        for col, data in g.edges[etype].data.items():\n",
    "            train_g.edges[etype].data[col] = data[train_g.edges[etype].data[dgl.EID]]\n",
    "\n",
    "    return train_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indicies = np.arange(len(df_playlists))\n",
    "train_g = build_train_graph(g, train_indicies, 'playlist', 'track', 'contains', 'contained_by' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 HEAD POS NEG Tracks sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemToItemBatchSampler(IterableDataset):\n",
    "    def __init__(self, g, user_type, item_type, batch_size):\n",
    "        self.g = g\n",
    "        self.user_type = user_type\n",
    "        self.item_type = item_type\n",
    "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
    "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            heads = torch.randint(0, self.g.number_of_nodes(self.item_type), (self.batch_size,))\n",
    "            tails = dgl.sampling.random_walk(\n",
    "                self.g,\n",
    "                heads,\n",
    "                metapath=[self.item_to_user_etype, self.user_to_item_etype])[0][:, 2]\n",
    "            neg_tails = torch.randint(0, self.g.number_of_nodes(self.item_type), (self.batch_size,))\n",
    "\n",
    "            mask = (tails != -1)\n",
    "            yield heads[mask], tails[mask], neg_tails[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this block below generate a small graph data set that can be used to do parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heads = torch.randint(0, train_g.number_of_nodes('track'), (10000,))\n",
    "\n",
    "# tails = dgl.sampling.random_walk(\n",
    "#     train_g,\n",
    "#     heads,\n",
    "#     metapath=['contained_by', 'contains'])[0]\n",
    "# playlist_ids = torch.unique(tails[:, 1]).numpy()\n",
    "# track_ids = torch.unique(torch.cat([tails[:,0],tails[:,-1]])).numpy()\n",
    "# df_tracks_small = df_tracks[df_tracks['tid'].isin(track_ids)]\n",
    "# df_playlists_info_small = df_playlists_info[df_playlists_info['pid'].isin(playlist_ids)]\n",
    "# df_playlists_small  = df_playlists[df_playlists['pid'].isin(playlist_ids) & df_playlists['tid'].isin(track_ids)]\n",
    "# df_tracks_small = df_tracks_small.reset_index(drop=True)\n",
    "# df_playlists_info_small = df_playlists_info_small.reset_index(drop=True)\n",
    "# df_playlists_small = df_playlists_small.reset_index(drop=True)\n",
    "# new_track_uri_ids ={x:idx for idx, x in enumerate(list(df_tracks_small['tid']))}\n",
    "# new_playlists_ids ={x:idx for idx, x in enumerate(list(df_playlists_info_small['pid']))}\n",
    "# df_tracks_small['tid'] = [new_track_uri_ids[x] for x in list(df_tracks_small['tid'])]\n",
    "# df_playlists_info_small['pid'] = [new_playlists_ids[x] for x in list(df_playlists_info_small['pid'])]\n",
    "# df_playlists_small['pid'] = [new_playlists_ids[x] for x in list(df_playlists_small['pid'])]\n",
    "# df_playlists_small['tid'] = [new_track_uri_ids[x] for x in list(df_playlists_small['tid'])]\n",
    "# data = {\n",
    "#     'df_playlist': df_playlists_small,\n",
    "#     'df_playlist_info': df_playlists_info_small,\n",
    "#     'df_track': df_tracks_small\n",
    "# }\n",
    "# pickle.dump(data, open('ns_music_small_data.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampler below generate positive and negative edges\n",
    "- sample a batch of heads\n",
    "- do track -> playlist -> track random walk to find pairs of positive edges\n",
    "- random sample batch of nodes as negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sampler = ItemToItemBatchSampler(train_g, 'playlist', 'track', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iter = iter(batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads, tails, neg_tails = next(batch_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 652604, 1172189, 1171658,  775423, 2072876,  411679,  654767, 1671334,\n",
       "         1342078,  149534,   43313, 1643706,   29176, 1767177,  481002, 1210897,\n",
       "         1444569,  537707,  423477, 1186928, 1672399,  465615, 1665923, 1358648,\n",
       "         1345516,   60195,  138084, 1640883,  496928,  449051,  780300,  843284]),\n",
       " tensor([ 142868,  314177,    2517,  775421, 1302117,    3733,    2618, 1671286,\n",
       "         1342063,  860119,    9366,    8388,    3138,   13769,   10143,  915598,\n",
       "         1444561,  133257,  347474, 1186908,  579463,  111112,   58208,    7268,\n",
       "          900040,   27499,   93612,  115300, 1309897,  501567,  780299, 2204382]),\n",
       " tensor([ 303276, 1635463,  174702,  581917,  298855, 1163418,  709089,  257351,\n",
       "         1919806,  401042,  477965, 1527108, 1879487, 2224889, 2140501, 1751727,\n",
       "         1126472,  167081, 2131186,  755532,  333102,  219050, 1365535,  742104,\n",
       "         1823141,   35783, 1429677, 1943776, 1665372, 1594853, 1200184, 1386411]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads, tails, neg_tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2  Neighborhood sampler default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compact_and_copy(frontier, seeds):\n",
    "    block = dgl.to_block(frontier, seeds)\n",
    "    for col, data in frontier.edata.items():\n",
    "        if col == dgl.EID:\n",
    "            continue\n",
    "        block.edata[col] = data[block.edata[dgl.EID]]\n",
    "    return block\n",
    "\n",
    "class NeighborSampler(object):\n",
    "    def __init__(self, g, user_type, item_type, random_walk_length, random_walk_restart_prob,\n",
    "                 num_random_walks, num_neighbors, num_layers):\n",
    "        self.g = g\n",
    "        self.user_type = user_type\n",
    "        self.item_type = item_type\n",
    "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
    "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
    "        self.samplers = [\n",
    "            dgl.sampling.PinSAGESampler(g, item_type, user_type, random_walk_length,\n",
    "                                        random_walk_restart_prob, num_random_walks, num_neighbors)\n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "    def sample_blocks(self, seeds, heads=None, tails=None, neg_tails=None):\n",
    "        blocks = []\n",
    "        for sampler in self.samplers:\n",
    "            frontier = sampler(seeds)\n",
    "            if heads is not None:\n",
    "                eids = frontier.edge_ids(torch.cat([heads, heads]), torch.cat([tails, neg_tails]), return_uv=True)[2]\n",
    "                if len(eids) > 0:\n",
    "                    old_frontier = frontier\n",
    "                    frontier = dgl.remove_edges(old_frontier, eids)\n",
    "                    # print(old_frontier)\n",
    "                    # print(frontier)\n",
    "                    # print(frontier.edata['weights'])\n",
    "                    # frontier.edata['weights'] = old_frontier.edata['weights'][frontier.edata[dgl.EID]]\n",
    "            block = compact_and_copy(frontier, seeds)\n",
    "            seeds = block.srcdata[dgl.NID]\n",
    "            blocks.insert(0, block)\n",
    "        return blocks\n",
    "\n",
    "    def sample_from_item_pairs(self, heads, tails, neg_tails):\n",
    "        # Create a graph with positive connections only and another graph with negative\n",
    "        # connections only.\n",
    "        pos_graph = dgl.graph(\n",
    "            (heads, tails),\n",
    "            num_nodes=self.g.number_of_nodes(self.item_type))\n",
    "        neg_graph = dgl.graph(\n",
    "            (heads, neg_tails),\n",
    "            num_nodes=self.g.number_of_nodes(self.item_type))\n",
    "        pos_graph, neg_graph = dgl.compact_graphs([pos_graph, neg_graph])\n",
    "        seeds = pos_graph.ndata[dgl.NID]\n",
    "\n",
    "        blocks = self.sample_blocks(seeds, heads, tails, neg_tails)\n",
    "        return pos_graph, neg_graph, blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_features_to_blocks(blocks, g, ntype='track'):\n",
    "    \n",
    "    data = blocks[0].srcdata\n",
    "    \n",
    "    for col in g.nodes[ntype].data.keys():\n",
    "        if  col == dgl.NID:\n",
    "            continue\n",
    "        induced_nodes = data[dgl.NID]\n",
    "        data[col] = g.nodes[ntype].data[col][induced_nodes]\n",
    "\n",
    "    \n",
    "    data = blocks[-1].dstdata\n",
    "    for col in g.nodes[ntype].data.keys():\n",
    "        if  col == dgl.NID:\n",
    "            continue\n",
    "        induced_nodes = data[dgl.NID]\n",
    "        data[col] = g.nodes[ntype].data[col][induced_nodes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PinSAGECollator(object):\n",
    "    def __init__(self, sampler, g, ntype):\n",
    "        self.sampler = sampler\n",
    "        self.ntype = ntype\n",
    "        self.g = g\n",
    "\n",
    "    def collate_train(self, batches):\n",
    "        heads, tails, neg_tails = batches[0]\n",
    "        # Construct multilayer neighborhood via PinSAGE...\n",
    "        pos_graph, neg_graph, blocks = self.sampler.sample_from_item_pairs(heads, tails, neg_tails)\n",
    "        assign_features_to_blocks(blocks, self.g, self.ntype)\n",
    "\n",
    "        return pos_graph, neg_graph, blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** This is the neighbor graph generator\n",
    "\n",
    "- batch sampler: generate pos and negative pairs\n",
    "- neigbbor sampler:   generate neighbor graph of nodes from pos + neg pairs\n",
    "\n",
    "please go through the implementation details if you want to make modifications\n",
    "\n",
    "The output consists of:\n",
    "\n",
    "- pos graph: data structure storing positive pairs \n",
    "- neg graph: data structure storing negative pairs \n",
    "- blocks: data structure fascilitating message passing:\n",
    "    - blocks[0]  frontier 2 -> frontier 1 \n",
    "    - blocks[1]  frontier 1 -> nodes of interests\n",
    "\n",
    "corresponding nodes features are stored in blocks as well \n",
    "- `block.srcdata` src nodes data \n",
    "- `block.dstdata` dst nodes data\n",
    "\n",
    "**IMPORTANT** \n",
    "- The destination nodes are the destination end of edges in the graph. \n",
    "- The source nodes stored in `block.srcnode` are not only the source end of edges in the graph, it consists of:\n",
    "    - destination end nodes \n",
    "    - source end nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_sampler = NeighborSampler(train_g, 'playlist', 'track', \n",
    "                                   random_walk_length=2, random_walk_restart_prob=0.5, num_random_walks=10, num_neighbors=3, num_layers=2)\n",
    "collator = PinSAGECollator(neighbor_sampler, train_g, 'track')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    batch_sampler,\n",
    "    collate_fn=collator.collate_train,\n",
    "    num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_it = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_graph,neg_graph, blocks = next(dataloader_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_ID': tensor([1222908,  685010,  200852,  ..., 1405005, 2251956, 2251949]), 'danceability': tensor([1, 2, 3,  ..., 1, 1, 1]), 'energy': tensor([1, 2, 3,  ..., 3, 3, 3]), 'loudness': tensor([1, 3, 2,  ..., 2, 3, 3]), 'speechiness': tensor([1, 1, 2,  ..., 2, 2, 3]), 'acousticness': tensor([3, 1, 3,  ..., 2, 1, 2]), 'instrumentalness': tensor([1, 1, 2,  ..., 3, 3, 2]), 'liveness': tensor([2, 2, 2,  ..., 2, 3, 3]), 'valence': tensor([1, 2, 3,  ..., 2, 1, 2]), 'tempo': tensor([1, 2, 3,  ..., 3, 2, 3]), 'genre': tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'album_img_emb': tensor([[0.1468, 1.9877, 0.6605,  ..., 0.0424, 0.1162, 0.2592],\n",
       "        [0.1444, 2.0385, 0.3274,  ..., 0.0382, 0.0620, 0.1265],\n",
       "        [0.3310, 1.2132, 0.9204,  ..., 0.1687, 0.2099, 0.1162],\n",
       "        ...,\n",
       "        [0.0509, 0.7370, 0.5290,  ..., 0.6594, 0.3553, 0.6403],\n",
       "        [0.6656, 1.1754, 0.0608,  ..., 0.1465, 0.0809, 0.2653],\n",
       "        [0.6276, 1.6547, 0.5708,  ..., 0.0256, 0.0273, 0.3360]]), 'album_text_emb': tensor([[ 3.5587e-02, -1.1578e-02, -2.5223e-02,  ...,  1.9074e-02,\n",
       "         -1.4016e-03, -1.5625e-02],\n",
       "        [ 1.5970e-02, -3.0727e-02, -6.6265e-02,  ...,  2.7216e-02,\n",
       "         -4.0689e-03,  1.6101e-02],\n",
       "        [ 3.0871e-02, -5.2995e-02, -1.0928e-01,  ...,  2.7478e-02,\n",
       "         -6.6604e-03, -5.4481e-02],\n",
       "        ...,\n",
       "        [ 3.9839e-02, -4.4558e-02, -6.8928e-02,  ..., -1.2636e-02,\n",
       "          1.7609e-02, -5.4638e-02],\n",
       "        [-5.7590e-02, -1.1549e-02, -4.3014e-02,  ...,  9.2746e-02,\n",
       "          6.6148e-02,  3.3802e-02],\n",
       "        [ 1.4239e-02,  3.2505e-02,  3.0171e-03,  ..., -5.2148e-02,\n",
       "          8.7242e-02,  8.2217e-05]]), 'id': tensor([1222908,  685010,  200852,  ..., 1405005, 2251956, 2251949])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[0].srcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outline of model procedure:\n",
    "\n",
    "inputs: `pos_graph`, `neg_graph`, `block_0`, `block_1`\n",
    "\n",
    "- compute node projection for all nodes,  if you understand the section above you will see all we need to computes are:\n",
    "    - source nodes of block_0 \n",
    "    - destination nodes of block_1\n",
    "    \n",
    "- run 2 sage layers:\n",
    "    - layer 1 on block 0: frontier 2 -> frontier 1\n",
    "    - layer 2 on block 1: frontier 1 -> nodes of interests \n",
    "    \n",
    "- score on nodes of interests\n",
    "    - for nodes u, v,  dot(u,v) + bias(u) + bias(v)\n",
    "\n",
    "- loss function sum(neg_pairs_scores)  - sum(pos_pairs_scores) + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature projections:\n",
    "\n",
    "- music feature: \n",
    "    - each entry map to embedding of length 16\n",
    "    - total size 144 \n",
    "- genre feature: as it is  20 \n",
    "- album img feature: as it is  2048\n",
    "- track id feature: map to 128 embeddding\n",
    "\n",
    "\n",
    "Feature aggregation:\n",
    "\n",
    "- concatenate music feature, genre feature , album img feature : size 2212\n",
    "- Fully connected layer 2212x128 reduce the dimentionality of the concatenated feature \n",
    "- add id feature\n",
    "\n",
    "FC(concate[music, genre, img_emb]) + id_emb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_grad(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "def _init_input_modules(g, ntype):\n",
    "    module_dict = nn.ModuleDict()\n",
    "    \n",
    "    tracks_data = g.nodes[ntype].data\n",
    "    \n",
    "    module_dict['track_id'] = nn.Embedding(tracks_data['id'].max()+1, 128)\n",
    "    \n",
    "    for m in ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']: \n",
    "        module_dict[m] = nn.Embedding(tracks_data[m].max() + 1, 16)\n",
    "\n",
    "    return module_dict\n",
    "\n",
    "\n",
    "class LinearProjector(nn.Module):\n",
    "    \"\"\"\n",
    "    Projects each input feature of the graph linearly and sums them up\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, full_graph, ntype):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ntype = ntype\n",
    "        #self.fc = nn.Linear(164, 128)\n",
    "        self.fc = nn.Linear(2212, 128)\n",
    "        self.inputs = _init_input_modules(full_graph, ntype)\n",
    "\n",
    "    def forward(self, ndata):\n",
    "        \n",
    "        # get music feature\n",
    "        music_features = []\n",
    "        for c in ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']:\n",
    "\n",
    "            module = self.inputs[c]\n",
    "            music_features.append(module(ndata[c]))\n",
    "        music_features = torch.cat(music_features, dim=1)\n",
    "        \n",
    "        \n",
    "        # id embedding \n",
    "        id_embedding = self.inputs['track_id'](ndata['id'])\n",
    "        \n",
    "        # album feature \n",
    "        img_emb = ndata['album_img_emb']\n",
    "        \n",
    "        # genre \n",
    "        genre = ndata['genre']\n",
    "        \n",
    "        # concatenate \n",
    "        feature = torch.cat([music_features, genre, ndata['album_img_emb']], dim=1)\n",
    "        #feature = torch.cat([music_features, genre], dim=1)\n",
    "\n",
    "        projection = self.fc(feature) + id_embedding\n",
    "        \n",
    "        return projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 sage layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not too much to discuss, please understand every line of the the following if you intend to make model modification\n",
    "\n",
    "notice the changes in `itemtoitemscorer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class WeightedSAGEConv(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims, act=F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = act\n",
    "        self.Q = nn.Linear(input_dims, hidden_dims)\n",
    "        self.W = nn.Linear(input_dims + hidden_dims, output_dims)\n",
    "        self.reset_parameters()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_uniform_(self.Q.weight, gain=gain)\n",
    "        nn.init.xavier_uniform_(self.W.weight, gain=gain)\n",
    "        nn.init.constant_(self.Q.bias, 0)\n",
    "        nn.init.constant_(self.W.bias, 0)\n",
    "\n",
    "    def forward(self, g, h, weights):\n",
    "        \"\"\"\n",
    "        g : graph\n",
    "        h : node features\n",
    "        weights : scalar edge weights\n",
    "        \"\"\"\n",
    "        h_src, h_dst = h\n",
    "        with g.local_scope():\n",
    "            g.srcdata['n'] = self.act(self.Q(self.dropout(h_src)))\n",
    "            g.edata['w'] = weights.float()\n",
    "            g.update_all(fn.u_mul_e('n', 'w', 'm'), fn.sum('m', 'n'))\n",
    "            g.update_all(fn.copy_e('w', 'm'), fn.sum('m', 'ws'))\n",
    "            n = g.dstdata['n']\n",
    "            ws = g.dstdata['ws'].unsqueeze(1).clamp(min=1)\n",
    "            z = self.act(self.W(self.dropout(torch.cat([n / ws, h_dst], 1))))\n",
    "            z_norm = z.norm(2, 1, keepdim=True)\n",
    "            z_norm = torch.where(z_norm == 0, torch.tensor(1.).to(z_norm), z_norm)\n",
    "            z = z / z_norm\n",
    "            return z\n",
    "\n",
    "\n",
    "class SAGENet(nn.Module):\n",
    "    def __init__(self, hidden_dims, n_layers):\n",
    "        \"\"\"\n",
    "        g : DGLHeteroGraph\n",
    "            The user-item interaction graph.\n",
    "            This is only for finding the range of categorical variables.\n",
    "        item_textsets : torchtext.data.Dataset\n",
    "            The textual features of each item node.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.convs.append(WeightedSAGEConv(hidden_dims, hidden_dims, hidden_dims))\n",
    "\n",
    "    def forward(self, blocks, h):\n",
    "        for layer, block in zip(self.convs, blocks):\n",
    "            h_dst = h[:block.number_of_nodes('DST/' + block.ntypes[0])]\n",
    "            h = layer(block, (h, h_dst), block.edata['weights'])\n",
    "        return h\n",
    "class ItemToItemScorer(nn.Module):\n",
    "    def __init__(self, full_graph, ntype):\n",
    "        super().__init__()\n",
    "\n",
    "        n_nodes = full_graph.number_of_nodes(ntype)\n",
    "        self.bias = nn.Parameter(torch.zeros(n_nodes))\n",
    "\n",
    "    def _add_bias(self, edges):\n",
    "        bias_src = self.bias[edges.src[dgl.NID]]\n",
    "        bias_dst = self.bias[edges.dst[dgl.NID]]\n",
    "        return {'s': edges.data['s'] + bias_src + bias_dst}\n",
    "\n",
    "    def forward(self, item_item_graph, h):\n",
    "        \"\"\"\n",
    "        item_item_graph : graph consists of edges connecting the pairs\n",
    "        h : hidden state of every node\n",
    "        \"\"\"\n",
    "        with item_item_graph.local_scope():\n",
    "            item_item_graph.ndata['h'] = h\n",
    "            item_item_graph.apply_edges(fn.u_dot_v('h', 'h', 's'))\n",
    "            item_item_graph.edata['s'] = item_item_graph.edata['s'].flatten()\n",
    "            item_item_graph.apply_edges(self._add_bias)\n",
    "\n",
    "            pair_score = item_item_graph.edata['s']\n",
    "        return pair_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).detach().cpu().numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "class PinSAGEModel(nn.Module):\n",
    "    def __init__(self, full_graph, ntype, hidden_dims, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj = LinearProjector(full_graph, ntype)\n",
    "        self.sage = SAGENet(hidden_dims, n_layers)\n",
    "        self.scorer = ItemToItemScorer(full_graph, ntype)\n",
    "\n",
    "    def forward(self, pos_graph, neg_graph, blocks):\n",
    "        h_item = self.get_repr(blocks)\n",
    "        pos_score = self.scorer(pos_graph, h_item)\n",
    "        neg_score = self.scorer(neg_graph, h_item)\n",
    "        \n",
    "        #return h_item, pos_score, neg_score\n",
    "        auc = compute_auc(pos_score, neg_score)\n",
    "        return (neg_score - pos_score + 1).clamp(min=0), auc\n",
    "\n",
    "    def get_repr(self, blocks):\n",
    "        h_item = self.proj(blocks[0].srcdata)\n",
    "        h_item_dst = self.proj(blocks[-1].dstdata)\n",
    "        return h_item_dst + self.sage(blocks, h_item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PinSAGEModel(train_g, 'track', 128, 2)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_it = iter(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "losses = []\n",
    "for batch_id in  range(100000000):\n",
    "    pos_graph, neg_graph, blocks = next(dataloader_it)\n",
    "    # Copy to GPU\n",
    "    for i in range(len(blocks)):\n",
    "        blocks[i] = blocks[i].to(device)\n",
    "    pos_graph = pos_graph.to(device)\n",
    "    neg_graph = neg_graph.to(device)\n",
    "    \n",
    "    loss,auc = model(pos_graph, neg_graph, blocks)\n",
    "    loss = loss.mean()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if batch_id % 100 == 0:\n",
    "        print(loss, auc)\n",
    "        losses.append([loss.item(),auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "plt.plot(moving_average(np.array([x[0] for x in losses]), 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ming_env] *",
   "language": "python",
   "name": "conda-env-ming_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
