{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype, is_categorical\n",
    "import torch\n",
    "import pandas as pd \n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/mila/r/rebecca.salganik/'\n",
    "\n",
    "# os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_music_all_data = pickle.load(open(directory+'ns_music_all_data_ming.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlists = ns_music_all_data['df_playlist']\n",
    "df_playlists_info = ns_music_all_data['df_playlist_info']\n",
    "df_tracks = ns_music_all_data['df_track']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>tid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  tid\n",
       "0    0    0\n",
       "1  123    0\n",
       "2  218    0\n",
       "3  342    0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build Playlist-Track graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _series_to_tensor(series):\n",
    "    if is_categorical(series):\n",
    "        return torch.LongTensor(series.cat.codes.values.astype('int64'))\n",
    "    else:       # numeric\n",
    "        return torch.FloatTensor(series.values)\n",
    "\n",
    "class PandasGraphBuilder(object):\n",
    "    def __init__(self):\n",
    "        self.entity_tables = {}\n",
    "        self.relation_tables = {}\n",
    "\n",
    "        self.entity_pk_to_name = {}     # mapping from primary key name to entity name\n",
    "        self.entity_pk = {}             # mapping from entity name to primary key\n",
    "        self.entity_key_map = {}        # mapping from entity names to primary key values\n",
    "        self.num_nodes_per_type = {}\n",
    "        self.edges_per_relation = {}\n",
    "        self.relation_name_to_etype = {}\n",
    "        self.relation_src_key = {}      # mapping from relation name to source key\n",
    "        self.relation_dst_key = {}      # mapping from relation name to destination key\n",
    "\n",
    "    def add_entities(self, entity_table, primary_key, name):\n",
    "        entities = entity_table[primary_key].astype('category')\n",
    "        if not (entities.value_counts() == 1).all():\n",
    "            raise ValueError('Different entity with the same primary key detected.')\n",
    "        # preserve the category order in the original entity table\n",
    "        entities = entities.cat.reorder_categories(entity_table[primary_key].values)\n",
    "\n",
    "        self.entity_pk_to_name[primary_key] = name\n",
    "        self.entity_pk[name] = primary_key\n",
    "        self.num_nodes_per_type[name] = entity_table.shape[0]\n",
    "        self.entity_key_map[name] = entities\n",
    "        self.entity_tables[name] = entity_table\n",
    "\n",
    "    def add_binary_relations(self, relation_table, source_key, destination_key, name):\n",
    "        src = relation_table[source_key].astype('category')\n",
    "        src = src.cat.set_categories(\n",
    "            self.entity_key_map[self.entity_pk_to_name[source_key]].cat.categories)\n",
    "        dst = relation_table[destination_key].astype('category')\n",
    "        dst = dst.cat.set_categories(\n",
    "            self.entity_key_map[self.entity_pk_to_name[destination_key]].cat.categories)\n",
    "        if src.isnull().any():\n",
    "            raise ValueError(\n",
    "                'Some source entities in relation %s do not exist in entity %s.' %\n",
    "                (name, source_key))\n",
    "        if dst.isnull().any():\n",
    "            raise ValueError(\n",
    "                'Some destination entities in relation %s do not exist in entity %s.' %\n",
    "                (name, destination_key))\n",
    "\n",
    "        srctype = self.entity_pk_to_name[source_key]\n",
    "        dsttype = self.entity_pk_to_name[destination_key]\n",
    "        etype = (srctype, name, dsttype)\n",
    "        self.relation_name_to_etype[name] = etype\n",
    "        self.edges_per_relation[etype] = (src.cat.codes.values.astype('int64'), dst.cat.codes.values.astype('int64'))\n",
    "        self.relation_tables[name] = relation_table\n",
    "        self.relation_src_key[name] = source_key\n",
    "        self.relation_dst_key[name] = destination_key\n",
    "\n",
    "    def build(self):\n",
    "        # Create heterograph\n",
    "        graph = dgl.heterograph(self.edges_per_relation, self.num_nodes_per_type)\n",
    "        return graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build bipartite heterogenous graph:\n",
    "\n",
    "- track is identified by tid\n",
    "- playlist is identified by pid \n",
    "- edge contains : play list contains track \n",
    "- edge contained_by: track is contained by playlist\n",
    "\n",
    "\n",
    "ids of nodes in graph and rows in dataset are in the same order:\n",
    "- 1st track node is track with tid =1 \n",
    "- 1st playlist node is play list with pid = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = PandasGraphBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlists_info = df_playlists_info.sort_values('pid').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Throwbacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Awesome Playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>korean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid              name\n",
       "0    0        Throwbacks\n",
       "1    1  Awesome Playlist\n",
       "2    2           korean "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_playlists_info.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = PandasGraphBuilder()\n",
    "graph_builder.add_entities(df_tracks, 'tid', 'track')\n",
    "graph_builder.add_entities(df_playlists_info, 'pid', 'playlist')\n",
    "graph_builder.add_binary_relations(df_playlists, 'pid', 'tid', 'contains')\n",
    "graph_builder.add_binary_relations(df_playlists, 'tid', 'pid', 'contained_by')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graph_builder.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features to graph\n",
    "- music features are stored as long tensors (categorical, to be embedded)\n",
    "- genre, album_img_emb, album_text_emb are stored as numerical features \n",
    "- track id, play list id are also included, can be embedded as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']:\n",
    "    \n",
    "    g.nodes['track'].data[key] = torch.LongTensor(df_tracks[key].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['track'].data['genre'] = torch.tensor(np.asarray(list(df_tracks['genre'].values))).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CPU usage is:  9.1\n",
      "RAM memory % used: 21.4\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "print('The CPU usage is: ', psutil.cpu_percent(4))\n",
    "print('RAM memory % used:', psutil.virtual_memory()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.nodes['track'].data['album_img_emb'] = torch.tensor(np.asarray(list(df_tracks['album_img_emb'].values)))\n",
    "# g.nodes['track'].data['album_text_emb'] = torch.tensor(np.asarray(list(df_tracks['album_text_emb'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['playlist'].data['id'] = torch.arange(g.number_of_nodes('playlist'))\n",
    "g.nodes['track'].data['id'] = torch.arange(g.number_of_nodes('track'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeSpace(data={'id': tensor([     0,      1,      2,  ..., 999997, 999998, 999999])})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes['playlist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeSpace(data={'danceability': tensor([3, 3, 3,  ..., 3, 2, 1]), 'energy': tensor([3, 3, 3,  ..., 2, 3, 2]), 'loudness': tensor([2, 3, 2,  ..., 2, 2, 2]), 'speechiness': tensor([3, 3, 3,  ..., 2, 1, 1]), 'acousticness': tensor([1, 1, 1,  ..., 1, 1, 2]), 'instrumentalness': tensor([2, 2, 1,  ..., 2, 1, 2]), 'liveness': tensor([1, 3, 1,  ..., 2, 2, 2]), 'valence': tensor([3, 3, 3,  ..., 2, 3, 1]), 'tempo': tensor([2, 3, 1,  ..., 1, 3, 2]), 'genre': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'id': tensor([      0,       1,       2,  ..., 2262187, 2262188, 2262189])})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes['track']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_pid(df, group_by_val, train_size=.8, val_size = .1, test_size=.1):\n",
    "    print(\"***Splitting by Playlist***\")\n",
    "    train_pids, all_test_pids = train_test_split(df[group_by_val].unique(), test_size=test_size+val_size, random_state=1)\n",
    "    all_test = df[df.pid.isin(all_test_pids)]\n",
    "    val_pids, test_pids = train_test_split(all_test[group_by_val].unique(), test_size=val_size, random_state=1)\n",
    "    train = df[df.pid.isin(train_pids)]\n",
    "    val = df[df.pid.isin(val_pids)]\n",
    "    test = df[df.pid.isin(test_pids)]\n",
    "    \n",
    "    print(\"***Current Set has {} pids in train, {} pids in val, {} pids in test\".format(len(train_pids), len(val_pids), len(test_pids)))\n",
    "    return list(train.index), list(val.index), list(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Splitting by Playlist***\n",
      "***Current Set has 800000 pids in train, 180000 pids in val, 20000 pids in test\n"
     ]
    }
   ],
   "source": [
    "train_indices, val_indices, test_indices = split_by_pid(df = df_playlists, group_by_val = 'pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ssp\n",
    "def build_val_test_matrix(g, val_indices, test_indices, utype, itype, etype):\n",
    "    n_users = g.number_of_nodes(utype)\n",
    "    n_items = g.number_of_nodes(itype)\n",
    "    val_src, val_dst = g.find_edges(val_indices, etype=etype)\n",
    "    test_src, test_dst = g.find_edges(test_indices, etype=etype)\n",
    "    val_src = val_src.numpy()\n",
    "    val_dst = val_dst.numpy()\n",
    "    test_src = test_src.numpy()\n",
    "    test_dst = test_dst.numpy()\n",
    "    val_matrix = ssp.coo_matrix((np.ones_like(val_src), (val_src, val_dst)), (n_users, n_items))\n",
    "    test_matrix = ssp.coo_matrix((np.ones_like(test_src), (test_src, test_dst)), (n_users, n_items))\n",
    "\n",
    "    return val_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_matrix, test_matrix = build_val_test_matrix(g, val_indices, test_indices, 'playlist', 'track', 'contains')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "        'train-graph': train_g,\n",
    "        'val-matrix': val_matrix,\n",
    "        'test-matrix': test_matrix,\n",
    "        'item-texts': None,\n",
    "        'item-images': None,\n",
    "        'user-type': 'playlist',\n",
    "        'item-type': 'track',\n",
    "        'user-to-item-type': 'contained_by',\n",
    "        'item-to-user-type': 'contains',\n",
    "        'timestamp-edge-column': None}\n",
    "with open(directory+\"dataset_without_im.pkl\", 'wb') as f:\n",
    "        pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_graph(g, train_indices, utype, itype, etype, etype_rev):\n",
    "    train_g = g.edge_subgraph(\n",
    "        {etype: train_indices, etype_rev: train_indices},\n",
    "        relabel_nodes=False)\n",
    "\n",
    "    # copy features\n",
    "    for ntype in g.ntypes:\n",
    "        for col, data in g.nodes[ntype].data.items():\n",
    "            train_g.nodes[ntype].data[col] = data\n",
    "    for etype in g.etypes:\n",
    "        for col, data in g.edges[etype].data.items():\n",
    "            train_g.edges[etype].data[col] = data[train_g.edges[etype].data[dgl.EID]]\n",
    "\n",
    "    return train_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indices = np.arange(len(df_playlists))\n",
    "train_g = build_train_graph(g, train_indices, 'playlist', 'track', 'contains', 'contained_by' )\n",
    "val_g = build_train_graph(g, val_indices, 'playlist', 'track', 'contains', 'contained_by')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 HEAD POS NEG Tracks sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemToItemBatchSampler(IterableDataset):\n",
    "    def __init__(self, g, user_type, item_type, batch_size):\n",
    "        self.g = g\n",
    "        self.user_type = user_type\n",
    "        self.item_type = item_type\n",
    "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
    "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            heads = torch.randint(0, self.g.number_of_nodes(self.item_type), (self.batch_size,))\n",
    "            tails = dgl.sampling.random_walk(\n",
    "                self.g,\n",
    "                heads,\n",
    "                metapath=[self.item_to_user_etype, self.user_to_item_etype])[0][:, 2]\n",
    "            neg_tails = torch.randint(0, self.g.number_of_nodes(self.item_type), (self.batch_size,))\n",
    "\n",
    "            mask = (tails != -1)\n",
    "            yield heads[mask], tails[mask], neg_tails[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this block below generate a small graph data set that can be used to do parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heads = torch.randint(0, train_g.number_of_nodes('track'), (10000,))\n",
    "\n",
    "# tails = dgl.sampling.random_walk(\n",
    "#     train_g,\n",
    "#     heads,\n",
    "#     metapath=['contained_by', 'contains'])[0]\n",
    "# playlist_ids = torch.unique(tails[:, 1]).numpy()\n",
    "# track_ids = torch.unique(torch.cat([tails[:,0],tails[:,-1]])).numpy()\n",
    "# df_tracks_small = df_tracks[df_tracks['tid'].isin(track_ids)]\n",
    "# df_playlists_info_small = df_playlists_info[df_playlists_info['pid'].isin(playlist_ids)]\n",
    "# df_playlists_small  = df_playlists[df_playlists['pid'].isin(playlist_ids) & df_playlists['tid'].isin(track_ids)]\n",
    "# df_tracks_small = df_tracks_small.reset_index(drop=True)\n",
    "# df_playlists_info_small = df_playlists_info_small.reset_index(drop=True)\n",
    "# df_playlists_small = df_playlists_small.reset_index(drop=True)\n",
    "# new_track_uri_ids ={x:idx for idx, x in enumerate(list(df_tracks_small['tid']))}\n",
    "# new_playlists_ids ={x:idx for idx, x in enumerate(list(df_playlists_info_small['pid']))}\n",
    "# df_tracks_small['tid'] = [new_track_uri_ids[x] for x in list(df_tracks_small['tid'])]\n",
    "# df_playlists_info_small['pid'] = [new_playlists_ids[x] for x in list(df_playlists_info_small['pid'])]\n",
    "# df_playlists_small['pid'] = [new_playlists_ids[x] for x in list(df_playlists_small['pid'])]\n",
    "# df_playlists_small['tid'] = [new_track_uri_ids[x] for x in list(df_playlists_small['tid'])]\n",
    "# data = {\n",
    "#     'df_playlist': df_playlists_small,\n",
    "#     'df_playlist_info': df_playlists_info_small,\n",
    "#     'df_track': df_tracks_small\n",
    "# }\n",
    "# pickle.dump(data, open('ns_music_small_data.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampler below generate positive and negative edges\n",
    "- sample a batch of heads\n",
    "- do track -> playlist -> track random walk to find pairs of positive edges\n",
    "- random sample batch of nodes as negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sampler = ItemToItemBatchSampler(train_g, 'playlist', 'track', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iter = iter(batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads, tails, neg_tails = next(batch_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 413061,  879847, 1159623, 1749339,  262613, 1690124, 2200180,  607687,\n",
       "         1476803,  247953,  103258, 1321047, 1339018,  828669, 1311840, 2196059,\n",
       "         1786005, 1690300,  791193,  103203,  139474,  816963, 1666529,  866276,\n",
       "         1782598,  253172,  666214, 1181945,  890482]),\n",
       " tensor([  20202,  879834,   50731,  522094,  262617, 1690104, 1311800,    4894,\n",
       "           15503,   28590,   51565, 1390839, 1339031,  828726,  497469,   27669,\n",
       "          508329,  154006, 1217686,  366362,  140033,   72889,  199389,   20171,\n",
       "           16341,   37195,   31381,  124773,  146017]),\n",
       " tensor([1279967, 2205394, 1001195, 1603003,  362784,  556222, 1405729,  164426,\n",
       "         1501382,  737591,  760490, 2174565, 2138340,  130636, 1908287, 2187245,\n",
       "          266175,  472640, 1087661, 2191565, 1691016, 1953413, 2051470,  170384,\n",
       "         1915228,  258887,  339759,  579151,  228380]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads, tails, neg_tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2  Neighborhood sampler default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compact_and_copy(frontier, seeds):\n",
    "    block = dgl.to_block(frontier, seeds)\n",
    "    for col, data in frontier.edata.items():\n",
    "        if col == dgl.EID:\n",
    "            continue\n",
    "        block.edata[col] = data[block.edata[dgl.EID]]\n",
    "    return block\n",
    "\n",
    "class NeighborSampler(object):\n",
    "    def __init__(self, g, user_type, item_type, random_walk_length, random_walk_restart_prob,\n",
    "                 num_random_walks, num_neighbors, num_layers):\n",
    "        self.g = g\n",
    "        self.user_type = user_type\n",
    "        self.item_type = item_type\n",
    "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
    "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
    "        self.samplers = [\n",
    "            dgl.sampling.PinSAGESampler(g, item_type, user_type, random_walk_length,\n",
    "                                        random_walk_restart_prob, num_random_walks, num_neighbors)\n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "    def sample_blocks(self, seeds, heads=None, tails=None, neg_tails=None):\n",
    "        blocks = []\n",
    "        for sampler in self.samplers:\n",
    "            frontier = sampler(seeds)\n",
    "            if heads is not None:\n",
    "                eids = frontier.edge_ids(torch.cat([heads, heads]), torch.cat([tails, neg_tails]), return_uv=True)[2]\n",
    "                if len(eids) > 0:\n",
    "                    old_frontier = frontier\n",
    "                    frontier = dgl.remove_edges(old_frontier, eids)\n",
    "                    # print(old_frontier)\n",
    "                    # print(frontier)\n",
    "                    # print(frontier.edata['weights'])\n",
    "                    # frontier.edata['weights'] = old_frontier.edata['weights'][frontier.edata[dgl.EID]]\n",
    "            block = compact_and_copy(frontier, seeds)\n",
    "            seeds = block.srcdata[dgl.NID]\n",
    "            blocks.insert(0, block)\n",
    "        return blocks\n",
    "\n",
    "    def sample_from_item_pairs(self, heads, tails, neg_tails):\n",
    "        # Create a graph with positive connections only and another graph with negative\n",
    "        # connections only.\n",
    "        pos_graph = dgl.graph(\n",
    "            (heads, tails),\n",
    "            num_nodes=self.g.number_of_nodes(self.item_type))\n",
    "        neg_graph = dgl.graph(\n",
    "            (heads, neg_tails),\n",
    "            num_nodes=self.g.number_of_nodes(self.item_type))\n",
    "        pos_graph, neg_graph = dgl.compact_graphs([pos_graph, neg_graph])\n",
    "        seeds = pos_graph.ndata[dgl.NID]\n",
    "\n",
    "        blocks = self.sample_blocks(seeds, heads, tails, neg_tails)\n",
    "        return pos_graph, neg_graph, blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_features_to_blocks(blocks, g, ntype='track'):\n",
    "    \n",
    "    data = blocks[0].srcdata\n",
    "    \n",
    "    for col in g.nodes[ntype].data.keys():\n",
    "        if  col == dgl.NID:\n",
    "            continue\n",
    "        induced_nodes = data[dgl.NID]\n",
    "        data[col] = g.nodes[ntype].data[col][induced_nodes]\n",
    "\n",
    "    \n",
    "    data = blocks[-1].dstdata\n",
    "    for col in g.nodes[ntype].data.keys():\n",
    "        if  col == dgl.NID:\n",
    "            continue\n",
    "        induced_nodes = data[dgl.NID]\n",
    "        data[col] = g.nodes[ntype].data[col][induced_nodes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PinSAGECollator(object):\n",
    "    def __init__(self, sampler, g, ntype):\n",
    "        self.sampler = sampler\n",
    "        self.ntype = ntype\n",
    "        self.g = g\n",
    "\n",
    "    def collate_train(self, batches):\n",
    "        heads, tails, neg_tails = batches[0]\n",
    "        # Construct multilayer neighborhood via PinSAGE...\n",
    "        pos_graph, neg_graph, blocks = self.sampler.sample_from_item_pairs(heads, tails, neg_tails)\n",
    "        assign_features_to_blocks(blocks, self.g, self.ntype)\n",
    "\n",
    "        return pos_graph, neg_graph, blocks\n",
    "    \n",
    "    def collate_test(self, samples):\n",
    "        batch = torch.LongTensor(samples)\n",
    "        blocks = self.sampler.sample_blocks(batch)\n",
    "        assign_features_to_blocks(blocks, self.g, self.ntype)\n",
    "        return blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** This is the neighbor graph generator\n",
    "\n",
    "- batch sampler: generate pos and negative pairs\n",
    "- neigbbor sampler:   generate neighbor graph of nodes from pos + neg pairs\n",
    "\n",
    "please go through the implementation details if you want to make modifications\n",
    "\n",
    "The output consists of:\n",
    "\n",
    "- pos graph: data structure storing positive pairs \n",
    "- neg graph: data structure storing negative pairs \n",
    "- blocks: data structure fascilitating message passing:\n",
    "    - blocks[0]  frontier 2 -> frontier 1 \n",
    "    - blocks[1]  frontier 1 -> nodes of interests\n",
    "\n",
    "corresponding nodes features are stored in blocks as well \n",
    "- `block.srcdata` src nodes data \n",
    "- `block.dstdata` dst nodes data\n",
    "\n",
    "**IMPORTANT** \n",
    "- The destination nodes are the destination end of edges in the graph. \n",
    "- The source nodes stored in `block.srcnode` are not only the source end of edges in the graph, it consists of:\n",
    "    - destination end nodes \n",
    "    - source end nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_sampler = NeighborSampler(train_g, 'playlist', 'track', \n",
    "                                   random_walk_length=2, random_walk_restart_prob=0.5, num_random_walks=10, num_neighbors=3, num_layers=2)\n",
    "collator = PinSAGECollator(neighbor_sampler, train_g, 'track')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    batch_sampler,\n",
    "    collate_fn=collator.collate_train,\n",
    "    num_workers=4) #was 8 \n",
    "dataloader_test = DataLoader(\n",
    "    batch_sampler,\n",
    "    collate_fn=collator.collate_test,\n",
    "    num_workers=4) #was 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_it = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_graph,neg_graph, blocks = next(dataloader_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_ID': tensor([ 946700, 1098320, 1478866,  ..., 1871281, 1081338, 1081348]), 'danceability': tensor([2, 1, 2,  ..., 2, 2, 2]), 'energy': tensor([3, 3, 1,  ..., 3, 3, 1]), 'loudness': tensor([3, 3, 2,  ..., 1, 2, 1]), 'speechiness': tensor([3, 3, 1,  ..., 3, 3, 3]), 'acousticness': tensor([2, 1, 3,  ..., 3, 3, 3]), 'instrumentalness': tensor([1, 2, 2,  ..., 1, 1, 1]), 'liveness': tensor([1, 1, 3,  ..., 3, 3, 3]), 'valence': tensor([3, 2, 3,  ..., 2, 2, 2]), 'tempo': tensor([3, 1, 2,  ..., 2, 3, 1]), 'genre': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'id': tensor([ 946700, 1098320, 1478866,  ..., 1871281, 1081338, 1081348])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[0].srcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outline of model procedure:\n",
    "\n",
    "inputs: `pos_graph`, `neg_graph`, `block_0`, `block_1`\n",
    "\n",
    "- compute node projection for all nodes,  if you understand the section above you will see all we need to computes are:\n",
    "    - source nodes of block_0 \n",
    "    - destination nodes of block_1\n",
    "    \n",
    "- run 2 sage layers:\n",
    "    - layer 1 on block 0: frontier 2 -> frontier 1\n",
    "    - layer 2 on block 1: frontier 1 -> nodes of interests \n",
    "    \n",
    "- score on nodes of interests\n",
    "    - for nodes u, v,  dot(u,v) + bias(u) + bias(v)\n",
    "\n",
    "- loss function sum(neg_pairs_scores)  - sum(pos_pairs_scores) + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature projections:\n",
    "\n",
    "- music feature: \n",
    "    - each entry map to embedding of length 16\n",
    "    - total size 144 \n",
    "- genre feature: as it is  20 \n",
    "- album img feature: as it is  2048\n",
    "- track id feature: map to 128 embeddding\n",
    "\n",
    "\n",
    "Feature aggregation:\n",
    "\n",
    "- concatenate music feature, genre feature , album img feature : size 2212\n",
    "- Fully connected layer 2212x128 reduce the dimentionality of the concatenated feature \n",
    "- add id feature\n",
    "\n",
    "FC(concate[music, genre, img_emb]) + id_emb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_grad(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "def _init_input_modules(g, ntype):\n",
    "    module_dict = nn.ModuleDict()\n",
    "    \n",
    "    tracks_data = g.nodes[ntype].data\n",
    "    \n",
    "    module_dict['track_id'] = nn.Embedding(tracks_data['id'].max()+1, 128)\n",
    "    \n",
    "    for m in ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']: \n",
    "        module_dict[m] = nn.Embedding(tracks_data[m].max() + 1, 16)\n",
    "\n",
    "    return module_dict\n",
    "\n",
    "\n",
    "# class LinearProjector(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Projects each input feature of the graph linearly and sums them up\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, full_graph, ntype):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.ntype = ntype\n",
    "#         #self.fc = nn.Linear(164, 128)\n",
    "#         self.fc = nn.Linear(2212, 128)\n",
    "#         self.inputs = _init_input_modules(full_graph, ntype)\n",
    "\n",
    "#     def forward(self, ndata):\n",
    "        \n",
    "#         # get music feature\n",
    "#         music_features = []\n",
    "#         for c in ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']:\n",
    "\n",
    "#             module = self.inputs[c]\n",
    "#             music_features.append(module(ndata[c]))\n",
    "#         music_features = torch.cat(music_features, dim=1)\n",
    "        \n",
    "        \n",
    "#         # id embedding \n",
    "#         id_embedding = self.inputs['track_id'](ndata['id'])\n",
    "        \n",
    "#         # album feature \n",
    "#         img_emb = ndata['album_img_emb']\n",
    "        \n",
    "#         # genre \n",
    "#         genre = ndata['genre']\n",
    "        \n",
    "#         # concatenate \n",
    "#         feature = torch.cat([music_features, genre, ndata['album_img_emb']], dim=1)\n",
    "#         #feature = torch.cat([music_features, genre], dim=1)\n",
    "\n",
    "#         projection = self.fc(feature) + id_embedding\n",
    "        \n",
    "#         return projection\n",
    "    \n",
    "class LinearProjector(nn.Module):\n",
    "    \"\"\"\n",
    "    Projects each input feature of the graph linearly and sums them up\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, full_graph, ntype):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ntype = ntype\n",
    "        self.fc = nn.Linear(164, 128)\n",
    "        #self.fc = nn.Linear(2212, 128)\n",
    "        self.inputs = _init_input_modules(full_graph, ntype)\n",
    "\n",
    "    def forward(self, ndata):\n",
    "        \n",
    "        # get music feature\n",
    "        music_features = []\n",
    "        for c in ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']:\n",
    "\n",
    "            module = self.inputs[c]\n",
    "            music_features.append(module(ndata[c]))\n",
    "        music_features = torch.cat(music_features, dim=1)\n",
    "        \n",
    "        \n",
    "#         # id embedding \n",
    "#         id_embedding = self.inputs['track_id'](ndata['id'])\n",
    "        \n",
    "#         # album feature \n",
    "#         img_emb = ndata['album_img_emb']\n",
    "        \n",
    "        # genre \n",
    "        genre = ndata['genre']\n",
    "        \n",
    "        # concatenate \n",
    "        #feature = torch.cat([music_features, genre, ndata['album_img_emb']], dim=1)\n",
    "        feature = torch.cat([music_features, genre], dim=1)\n",
    "\n",
    "        projection = self.fc(feature) #+ id_embedding\n",
    "        \n",
    "        return projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 sage layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not too much to discuss, please understand every line of the the following if you intend to make model modification\n",
    "\n",
    "notice the changes in `itemtoitemscorer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class WeightedSAGEConv(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims, act=F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = act\n",
    "        self.Q = nn.Linear(input_dims, hidden_dims)\n",
    "        self.W = nn.Linear(input_dims + hidden_dims, output_dims)\n",
    "        self.reset_parameters()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_uniform_(self.Q.weight, gain=gain)\n",
    "        nn.init.xavier_uniform_(self.W.weight, gain=gain)\n",
    "        nn.init.constant_(self.Q.bias, 0)\n",
    "        nn.init.constant_(self.W.bias, 0)\n",
    "\n",
    "    def forward(self, g, h, weights):\n",
    "        \"\"\"\n",
    "        g : graph\n",
    "        h : node features\n",
    "        weights : scalar edge weights\n",
    "        \"\"\"\n",
    "        h_src, h_dst = h\n",
    "        with g.local_scope():\n",
    "            g.srcdata['n'] = self.act(self.Q(self.dropout(h_src)))\n",
    "            g.edata['w'] = weights.float()\n",
    "            g.update_all(fn.u_mul_e('n', 'w', 'm'), fn.sum('m', 'n'))\n",
    "            g.update_all(fn.copy_e('w', 'm'), fn.sum('m', 'ws'))\n",
    "            n = g.dstdata['n']\n",
    "            ws = g.dstdata['ws'].unsqueeze(1).clamp(min=1)\n",
    "            z = self.act(self.W(self.dropout(torch.cat([n / ws, h_dst], 1))))\n",
    "            z_norm = z.norm(2, 1, keepdim=True)\n",
    "            z_norm = torch.where(z_norm == 0, torch.tensor(1.).to(z_norm), z_norm)\n",
    "            z = z / z_norm\n",
    "            return z\n",
    "\n",
    "\n",
    "class SAGENet(nn.Module):\n",
    "    def __init__(self, hidden_dims, n_layers):\n",
    "        \"\"\"\n",
    "        g : DGLHeteroGraph\n",
    "            The user-item interaction graph.\n",
    "            This is only for finding the range of categorical variables.\n",
    "        item_textsets : torchtext.data.Dataset\n",
    "            The textual features of each item node.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.convs.append(WeightedSAGEConv(hidden_dims, hidden_dims, hidden_dims))\n",
    "\n",
    "    def forward(self, blocks, h):\n",
    "        for layer, block in zip(self.convs, blocks):\n",
    "            h_dst = h[:block.number_of_nodes('DST/' + block.ntypes[0])]\n",
    "            h = layer(block, (h, h_dst), block.edata['weights'])\n",
    "        return h\n",
    "\n",
    "class ItemToItemScorer(nn.Module):\n",
    "    def __init__(self, full_graph, ntype):\n",
    "        super().__init__()\n",
    "\n",
    "        n_nodes = full_graph.number_of_nodes(ntype)\n",
    "        self.bias = nn.Parameter(torch.zeros(n_nodes))\n",
    "\n",
    "    def _add_bias(self, edges):\n",
    "        bias_src = self.bias[edges.src[dgl.NID]]\n",
    "        bias_dst = self.bias[edges.dst[dgl.NID]]\n",
    "        return {'s': edges.data['s'] + bias_src + bias_dst}\n",
    "\n",
    "    def forward(self, item_item_graph, h):\n",
    "        \"\"\"\n",
    "        item_item_graph : graph consists of edges connecting the pairs\n",
    "        h : hidden state of every node\n",
    "        \"\"\"\n",
    "        with item_item_graph.local_scope():\n",
    "            item_item_graph.ndata['h'] = h\n",
    "            item_item_graph.apply_edges(fn.u_dot_v('h', 'h', 's'))\n",
    "            item_item_graph.edata['s'] = item_item_graph.edata['s'].flatten()\n",
    "            item_item_graph.apply_edges(self._add_bias)\n",
    "\n",
    "            pair_score = item_item_graph.edata['s']\n",
    "        return pair_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, ndcg_score\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).detach().cpu().numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "class PinSAGEModel(nn.Module):\n",
    "    def __init__(self, full_graph, ntype, hidden_dims, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj = LinearProjector(full_graph, ntype)\n",
    "        self.sage = SAGENet(hidden_dims, n_layers)\n",
    "        self.scorer = ItemToItemScorer(full_graph, ntype)\n",
    "\n",
    "    def forward(self, pos_graph, neg_graph, blocks):\n",
    "        h_item = self.get_repr(blocks)\n",
    "        pos_score = self.scorer(pos_graph, h_item)\n",
    "        neg_score = self.scorer(neg_graph, h_item)\n",
    "        \n",
    "        #return h_item, pos_score, neg_score\n",
    "        auc = compute_auc(pos_score, neg_score)\n",
    "        return (neg_score - pos_score + 1).clamp(min=0), auc \n",
    "\n",
    "\n",
    "    def get_repr(self, blocks):\n",
    "        h_item = self.proj(blocks[0].srcdata)\n",
    "        h_item_dst = self.proj(blocks[-1].dstdata)\n",
    "        return h_item_dst + self.sage(blocks, h_item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PinSAGEModel(train_g, 'track', 128, 2)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_matrix = val_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_it = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2058, device='cuda:0', grad_fn=<MeanBackward0>) 0.6826222684703434\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 72779, 72910, 72911, 73169) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSocketClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_64599/3602153148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpos_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Copy to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 72779, 72910, 72911, 73169) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "losses = []\n",
    "for batch_id in  range(100000000):\n",
    "    pos_graph, neg_graph, blocks = next(dataloader_it)\n",
    "    # Copy to GPU\n",
    "    for i in range(len(blocks)):\n",
    "        blocks[i] = blocks[i].to(device)\n",
    "    pos_graph = pos_graph.to(device)\n",
    "    neg_graph = neg_graph.to(device)\n",
    "    \n",
    "    loss, auc = model(pos_graph, neg_graph, blocks)\n",
    "    \n",
    "    loss = loss.mean()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if batch_id % 100 == 0:\n",
    "        print(loss, auc)\n",
    "        losses.append([loss.item(),auc])\n",
    "        \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    item_batches = torch.arange(g.number_of_nodes(item_ntype)).split(args.batch_size)\n",
    "    h_item_batches = []\n",
    "    for blocks in dataloader_test:\n",
    "        for i in range(len(blocks)):\n",
    "            blocks[i] = blocks[i].to(device)\n",
    "\n",
    "        h_item_batches.append(model.get_repr(blocks))\n",
    "    h_item = torch.cat(h_item_batches, 0)\n",
    "\n",
    "    print(evaluation.evaluate_nn(dataset, h_item, args.k, args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "plt.plot(moving_average(np.array([x[0] for x in losses]), 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsv3",
   "language": "python",
   "name": "nsv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
