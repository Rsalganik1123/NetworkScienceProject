{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import dgl\n",
    "\n",
    "import os \n",
    "import sys \n",
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype, is_categorical\n",
    "import torch\n",
    "import pandas as pd \n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from sklearn.metrics import roc_auc_score, ndcg_score\n",
    "import tqdm \n",
    "\n",
    "# import layers\n",
    "# import sampler as sampler_module\n",
    "# import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemToItemBatchSampler(IterableDataset):\n",
    "    def __init__(self, g, user_type, item_type, batch_size):\n",
    "        self.g = g\n",
    "        self.user_type = user_type\n",
    "        self.item_type = item_type\n",
    "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
    "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            heads = torch.randint(0, self.g.number_of_nodes(self.item_type), (self.batch_size,))\n",
    "            tails = dgl.sampling.random_walk(\n",
    "                self.g,\n",
    "                heads,\n",
    "                metapath=[self.item_to_user_etype, self.user_to_item_etype])[0][:, 2]\n",
    "            neg_tails = torch.randint(0, self.g.number_of_nodes(self.item_type), (self.batch_size,))\n",
    "\n",
    "            mask = (tails != -1)\n",
    "            yield heads[mask], tails[mask], neg_tails[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbourhood Sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact_and_copy(frontier, seeds):\n",
    "    block = dgl.to_block(frontier, seeds)\n",
    "    for col, data in frontier.edata.items():\n",
    "        if col == dgl.EID:\n",
    "            continue\n",
    "        block.edata[col] = data[block.edata[dgl.EID]]\n",
    "    return block\n",
    "\n",
    "class NeighborSampler(object):\n",
    "    def __init__(self, g, user_type, item_type, random_walk_length, random_walk_restart_prob,\n",
    "                 num_random_walks, num_neighbors, num_layers):\n",
    "        self.g = g\n",
    "        self.user_type = user_type\n",
    "        self.item_type = item_type\n",
    "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
    "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
    "        self.samplers = [\n",
    "            dgl.sampling.PinSAGESampler(g, item_type, user_type, random_walk_length,\n",
    "                                        random_walk_restart_prob, num_random_walks, num_neighbors)\n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "    def sample_blocks(self, seeds, heads=None, tails=None, neg_tails=None):\n",
    "        blocks = []\n",
    "        for sampler in self.samplers:\n",
    "            frontier = sampler(seeds)\n",
    "            if heads is not None:\n",
    "                eids = frontier.edge_ids(torch.cat([heads, heads]), torch.cat([tails, neg_tails]), return_uv=True)[2]\n",
    "                if len(eids) > 0:\n",
    "                    old_frontier = frontier\n",
    "                    frontier = dgl.remove_edges(old_frontier, eids)\n",
    "                    # print(old_frontier)\n",
    "                    # print(frontier)\n",
    "                    # print(frontier.edata['weights'])\n",
    "                    # frontier.edata['weights'] = old_frontier.edata['weights'][frontier.edata[dgl.EID]]\n",
    "            block = compact_and_copy(frontier, seeds)\n",
    "            seeds = block.srcdata[dgl.NID]\n",
    "            blocks.insert(0, block)\n",
    "        return blocks\n",
    "\n",
    "    def sample_from_item_pairs(self, heads, tails, neg_tails):\n",
    "        # Create a graph with positive connections only and another graph with negative\n",
    "        # connections only.\n",
    "        pos_graph = dgl.graph(\n",
    "            (heads, tails),\n",
    "            num_nodes=self.g.number_of_nodes(self.item_type))\n",
    "        neg_graph = dgl.graph(\n",
    "            (heads, neg_tails),\n",
    "            num_nodes=self.g.number_of_nodes(self.item_type))\n",
    "        pos_graph, neg_graph = dgl.compact_graphs([pos_graph, neg_graph])\n",
    "        seeds = pos_graph.ndata[dgl.NID]\n",
    "\n",
    "        blocks = self.sample_blocks(seeds, heads, tails, neg_tails)\n",
    "        return pos_graph, neg_graph, blocks\n",
    "\n",
    "def assign_features_to_blocks(blocks, g, ntype='track'):\n",
    "    \n",
    "    data = blocks[0].srcdata\n",
    "    \n",
    "    for col in g.nodes[ntype].data.keys():\n",
    "        if  col == dgl.NID:\n",
    "            continue\n",
    "        induced_nodes = data[dgl.NID]\n",
    "        data[col] = g.nodes[ntype].data[col][induced_nodes]\n",
    "\n",
    "    \n",
    "    data = blocks[-1].dstdata\n",
    "    for col in g.nodes[ntype].data.keys():\n",
    "        if  col == dgl.NID:\n",
    "            continue\n",
    "        induced_nodes = data[dgl.NID]\n",
    "        data[col] = g.nodes[ntype].data[col][induced_nodes]\n",
    "\n",
    "class PinSAGECollator(object):\n",
    "    def __init__(self, sampler, g, ntype):\n",
    "        self.sampler = sampler\n",
    "        self.ntype = ntype\n",
    "        self.g = g\n",
    "\n",
    "    def collate_train(self, batches):\n",
    "        heads, tails, neg_tails = batches[0]\n",
    "        # Construct multilayer neighborhood via PinSAGE...\n",
    "        pos_graph, neg_graph, blocks = self.sampler.sample_from_item_pairs(heads, tails, neg_tails)\n",
    "        assign_features_to_blocks(blocks, self.g, self.ntype)\n",
    "\n",
    "        return pos_graph, neg_graph, blocks\n",
    "    \n",
    "    def collate_test(self, samples):\n",
    "        batch = torch.LongTensor(samples) \n",
    "        blocks = self.sampler.sample_blocks(batch)\n",
    "        assign_features_to_blocks(blocks, self.g, self.ntype)\n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_grad(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "def _init_input_modules(g, ntype):\n",
    "    module_dict = nn.ModuleDict()\n",
    "    \n",
    "    tracks_data = g.nodes[ntype].data\n",
    "    \n",
    "    module_dict['track_id'] = nn.Embedding(tracks_data['id'].max()+1, 128)\n",
    "    \n",
    "    for m in ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']: \n",
    "        module_dict[m] = nn.Embedding(tracks_data[m].max() + 1, 16)\n",
    "\n",
    "    return module_dict\n",
    "\n",
    "class LinearProjector(nn.Module):\n",
    "    \"\"\"\n",
    "    Projects each input feature of the graph linearly and sums them up\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, full_graph, ntype):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ntype = ntype\n",
    "        self.fc = nn.Linear(164, 128)\n",
    "        #self.fc = nn.Linear(2212, 128)\n",
    "        self.inputs = _init_input_modules(full_graph, ntype)\n",
    "\n",
    "    def forward(self, ndata):\n",
    "        \n",
    "        # get music feature\n",
    "        music_features = []\n",
    "        for c in ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']:\n",
    "\n",
    "            module = self.inputs[c]\n",
    "            music_features.append(module(ndata[c]))\n",
    "        music_features = torch.cat(music_features, dim=1)\n",
    "        \n",
    "        \n",
    "#         # id embedding \n",
    "#         id_embedding = self.inputs['track_id'](ndata['id'])\n",
    "        \n",
    "#         # album feature \n",
    "#         img_emb = ndata['album_img_emb']\n",
    "        \n",
    "        # genre \n",
    "        genre = ndata['genre']\n",
    "        \n",
    "        # concatenate \n",
    "        #feature = torch.cat([music_features, genre, ndata['album_img_emb']], dim=1)\n",
    "        feature = torch.cat([music_features, genre], dim=1)\n",
    "\n",
    "        projection = self.fc(feature) #+ id_embedding\n",
    "        \n",
    "        return projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageNet Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class WeightedSAGEConv(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims, act=F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = act\n",
    "        self.Q = nn.Linear(input_dims, hidden_dims)\n",
    "        self.W = nn.Linear(input_dims + hidden_dims, output_dims)\n",
    "        self.reset_parameters()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_uniform_(self.Q.weight, gain=gain)\n",
    "        nn.init.xavier_uniform_(self.W.weight, gain=gain)\n",
    "        nn.init.constant_(self.Q.bias, 0)\n",
    "        nn.init.constant_(self.W.bias, 0)\n",
    "\n",
    "    def forward(self, g, h, weights):\n",
    "        \"\"\"\n",
    "        g : graph\n",
    "        h : node features\n",
    "        weights : scalar edge weights\n",
    "        \"\"\"\n",
    "        h_src, h_dst = h\n",
    "        with g.local_scope():\n",
    "            g.srcdata['n'] = self.act(self.Q(self.dropout(h_src)))\n",
    "            g.edata['w'] = weights.float()\n",
    "            g.update_all(fn.u_mul_e('n', 'w', 'm'), fn.sum('m', 'n'))\n",
    "            g.update_all(fn.copy_e('w', 'm'), fn.sum('m', 'ws'))\n",
    "            n = g.dstdata['n']\n",
    "            ws = g.dstdata['ws'].unsqueeze(1).clamp(min=1)\n",
    "            z = self.act(self.W(self.dropout(torch.cat([n / ws, h_dst], 1))))\n",
    "            z_norm = z.norm(2, 1, keepdim=True)\n",
    "            z_norm = torch.where(z_norm == 0, torch.tensor(1.).to(z_norm), z_norm)\n",
    "            z = z / z_norm\n",
    "            return z\n",
    "\n",
    "\n",
    "class SAGENet(nn.Module):\n",
    "    def __init__(self, hidden_dims, n_layers):\n",
    "        \"\"\"\n",
    "        g : DGLHeteroGraph\n",
    "            The user-item interaction graph.\n",
    "            This is only for finding the range of categorical variables.\n",
    "        item_textsets : torchtext.data.Dataset\n",
    "            The textual features of each item node.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.convs.append(WeightedSAGEConv(hidden_dims, hidden_dims, hidden_dims))\n",
    "\n",
    "    def forward(self, blocks, h):\n",
    "        for layer, block in zip(self.convs, blocks):\n",
    "            h_dst = h[:block.number_of_nodes('DST/' + block.ntypes[0])]\n",
    "            h = layer(block, (h, h_dst), block.edata['weights'])\n",
    "        return h\n",
    "\n",
    "class ItemToItemScorer(nn.Module):\n",
    "    def __init__(self, full_graph, ntype):\n",
    "        super().__init__()\n",
    "\n",
    "        n_nodes = full_graph.number_of_nodes(ntype)\n",
    "        self.bias = nn.Parameter(torch.zeros(n_nodes))\n",
    "\n",
    "    def _add_bias(self, edges):\n",
    "        bias_src = self.bias[edges.src[dgl.NID]]\n",
    "        bias_dst = self.bias[edges.dst[dgl.NID]]\n",
    "        return {'s': edges.data['s'] + bias_src + bias_dst}\n",
    "\n",
    "    def forward(self, item_item_graph, h):\n",
    "        \"\"\"\n",
    "        item_item_graph : graph consists of edges connecting the pairs\n",
    "        h : hidden state of every node\n",
    "        \"\"\"\n",
    "        with item_item_graph.local_scope():\n",
    "            item_item_graph.ndata['h'] = h\n",
    "            item_item_graph.apply_edges(fn.u_dot_v('h', 'h', 's'))\n",
    "            item_item_graph.edata['s'] = item_item_graph.edata['s'].flatten()\n",
    "            item_item_graph.apply_edges(self._add_bias)\n",
    "\n",
    "            pair_score = item_item_graph.edata['s']\n",
    "        return pair_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).detach().cpu().numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "class PinSAGEModel(nn.Module):\n",
    "    def __init__(self, full_graph, ntype, hidden_dims, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj = LinearProjector(full_graph, ntype)\n",
    "        self.sage = SAGENet(hidden_dims, n_layers)\n",
    "        self.scorer = ItemToItemScorer(full_graph, ntype)\n",
    "\n",
    "    def forward(self, pos_graph, neg_graph, blocks):\n",
    "        h_item = self.get_repr(blocks)\n",
    "        pos_score = self.scorer(pos_graph, h_item)\n",
    "        neg_score = self.scorer(neg_graph, h_item)\n",
    "        \n",
    "        #return h_item, pos_score, neg_score\n",
    "        auc = compute_auc(pos_score, neg_score)\n",
    "        return (neg_score - pos_score + 1).clamp(min=0), auc \n",
    "\n",
    "\n",
    "    def get_repr(self, blocks):\n",
    "        h_item = self.proj(blocks[0].srcdata)\n",
    "        h_item_dst = self.proj(blocks[-1].dstdata)\n",
    "        return h_item_dst + self.sage(blocks, h_item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec(recommendations, ground_truth):\n",
    "    n_users, n_items = ground_truth.shape\n",
    "    K = recommendations.shape[1]\n",
    "    user_idx = np.repeat(np.arange(n_users), K)\n",
    "    item_idx = recommendations.flatten()\n",
    "    relevance = ground_truth[user_idx, item_idx].reshape((n_users, K))\n",
    "    hit = relevance.any(axis=1).mean()\n",
    "    return hit\n",
    "\n",
    "class LatestNNRecommender(object):\n",
    "    def __init__(self, user_ntype, item_ntype, user_to_item_etype, timestamp, batch_size):\n",
    "        self.user_ntype = user_ntype\n",
    "        self.item_ntype = item_ntype\n",
    "        self.user_to_item_etype = user_to_item_etype\n",
    "        self.batch_size = batch_size\n",
    "        self.timestamp = timestamp\n",
    "\n",
    "    def recommend(self, full_graph, K, h_user, h_item):\n",
    "        \"\"\"\n",
    "        Return a (n_user, K) matrix of recommended items for each user\n",
    "        \"\"\"\n",
    "        graph_slice = full_graph.edge_type_subgraph([self.user_to_item_etype])\n",
    "        n_users = full_graph.number_of_nodes(self.user_ntype)\n",
    "        latest_interactions = dgl.sampling.select_topk(graph_slice, 1, self.timestamp, edge_dir='out')\n",
    "        user, latest_items = latest_interactions.all_edges(form='uv', order='srcdst')\n",
    "        # each user should have at least one \"latest\" interaction\n",
    "        assert torch.equal(user, torch.arange(n_users))\n",
    "\n",
    "        recommended_batches = []\n",
    "        user_batches = torch.arange(n_users).split(self.batch_size)\n",
    "        for user_batch in user_batches:\n",
    "            latest_item_batch = latest_items[user_batch].to(device=h_item.device)\n",
    "            dist = h_item[latest_item_batch] @ h_item.t()\n",
    "            # exclude items that are already interacted\n",
    "            for i, u in enumerate(user_batch.tolist()):\n",
    "                interacted_items = full_graph.successors(u, etype=self.user_to_item_etype)\n",
    "                dist[i, interacted_items] = -np.inf\n",
    "            recommended_batches.append(dist.topk(K, 1)[1])\n",
    "\n",
    "        recommendations = torch.cat(recommended_batches, 0)\n",
    "        return recommendations\n",
    "\n",
    "\n",
    "def evaluate_nn(dataset, h_item, k, batch_size):\n",
    "    g = dataset['train-graph']\n",
    "    val_matrix = dataset['val-matrix'].tocsr()\n",
    "    test_matrix = dataset['test-matrix'].tocsr()\n",
    "    item_texts = dataset['item-texts']\n",
    "    user_ntype = dataset['user-type']\n",
    "    item_ntype = dataset['item-type']\n",
    "    user_to_item_etype = dataset['user-to-item-type']\n",
    "#     timestamp = dataset['timestamp-edge-column']\n",
    "\n",
    "    rec_engine = LatestNNRecommender(\n",
    "        user_ntype, item_ntype, user_to_item_etype, timestamp, batch_size)\n",
    "\n",
    "    recommendations = rec_engine.recommend(g, k, None, h_item).cpu().numpy()\n",
    "    return prec(recommendations, val_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/mila/r/rebecca.salganik/'\n",
    "with open(directory + 'dataset_without_im.pkl', 'rb') as f:\n",
    "        dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset['train-graph']\n",
    "val_matrix = dataset['val-matrix'].tocsr()\n",
    "test_matrix = dataset['test-matrix'].tocsr()\n",
    "item_texts = dataset['item-texts']\n",
    "user_ntype = dataset['user-type']\n",
    "item_ntype = dataset['item-type']\n",
    "user_to_item_etype = dataset['user-to-item-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign user and movie IDs and use them as features (to learn an individual trainable\n",
    "# embedding for each entity)\n",
    "g.nodes['playlist'].data['id'] = torch.arange(g.number_of_nodes('playlist'))\n",
    "g.nodes['track'].data['id'] = torch.arange(g.number_of_nodes('track'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampler\n",
    "batch_sampler = ItemToItemBatchSampler(g, 'playlist', 'track', 32)\n",
    "neighbor_sampler = NeighborSampler(g, 'playlist', 'track', \n",
    "                                   random_walk_length=2, random_walk_restart_prob=0.5, num_random_walks=10, num_neighbors=3, num_layers=2)\n",
    "collator = PinSAGECollator(neighbor_sampler, g, 'track')\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    batch_sampler,\n",
    "    collate_fn=collator.collate_train,\n",
    "    num_workers=4) \n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    batch_sampler,\n",
    "    collate_fn=collator.collate_test,\n",
    "    num_workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test_it = iter(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/mila/r/rebecca.salganik/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/mila/r/rebecca.salganik/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 40, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_98198/2478922114.py\", line 88, in collate_test\n    batch = torch.LongTensor(samples)\nTypeError: only integer tensors of a single element can be converted to an index\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_98198/4104410923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_test_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/mila/r/rebecca.salganik/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/mila/r/rebecca.salganik/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 40, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_98198/2478922114.py\", line 88, in collate_test\n    batch = torch.LongTensor(samples)\nTypeError: only integer tensors of a single element can be converted to an index\n"
     ]
    }
   ],
   "source": [
    "for block in iter(dataloader_test_it): \n",
    "    print(block)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = PinSAGEModel(g, 'track', 128, 2)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_it = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6530, device='cuda:0', grad_fn=<MeanBackward0>) 0.7166666666666668\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/mila/r/rebecca.salganik/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/mila/r/rebecca.salganik/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 40, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_98198/2478922114.py\", line 88, in collate_test\n    batch = torch.LongTensor(samples)\nTypeError: only integer tensors of a single element can be converted to an index\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_98198/2325477173.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mitem_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_ntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mh_item_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mblocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nsv3/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/mila/r/rebecca.salganik/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/mila/r/rebecca.salganik/.conda/envs/nsv3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 40, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_98198/2478922114.py\", line 88, in collate_test\n    batch = torch.LongTensor(samples)\nTypeError: only integer tensors of a single element can be converted to an index\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1 \n",
    "batches_per_epoch = 100 \n",
    "losses = []\n",
    "batch_size = 32 \n",
    "# For each batch of head-tail-negative triplets...\n",
    "for epoch_id in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_id in tqdm.trange(batches_per_epoch):\n",
    "        pos_graph, neg_graph, blocks = next(dataloader_it)\n",
    "        # Copy to GPU\n",
    "        for i in range(len(blocks)):\n",
    "            blocks[i] = blocks[i].to(device)\n",
    "        pos_graph = pos_graph.to(device)\n",
    "        neg_graph = neg_graph.to(device)\n",
    "\n",
    "        loss, auc = model(pos_graph, neg_graph, blocks)\n",
    "        loss = loss.mean() \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    if epoch_id % 10 == 0:\n",
    "        print(loss, auc)\n",
    "        losses.append([loss.item(),auc])\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        item_batches = torch.arange(g.number_of_nodes(item_ntype)).split(batch_size)\n",
    "        h_item_batches = []\n",
    "        for blocks in dataloader_test:\n",
    "            for i in range(len(blocks)):\n",
    "                blocks[i] = blocks[i].to(device)\n",
    "\n",
    "            h_item_batches.append(model.get_repr(blocks))\n",
    "        h_item = torch.cat(h_item_batches, 0)\n",
    "\n",
    "        print(evaluation.evaluate_nn(dataset, h_item, k, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsv3",
   "language": "python",
   "name": "nsv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
