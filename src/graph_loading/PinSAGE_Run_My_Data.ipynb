{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# !pip3 install dgl\n",
    "# !pip3 install torch \n",
    "# !pip3 install torchtext\n",
    "\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "import dgl\n",
    "import torch\n",
    "import torchtext\n",
    "import networkx as nx\n",
    "import sys \n",
    "sys.path.append('/Users/rebeccasalganik/Documents/School/2021-2022/Network Science/Capstone/PinSAGE-dgl/')\n",
    "from builder import PandasGraphBuilder\n",
    "from data_utils import *"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "directory = '/Users/rebeccasalganik/Documents/School/2021-2022/Network Science/Capstone/Spotify_Data/spotify_in_csv/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data = pd.read_pickle(directory+'train_track_data.pkl')\n",
    "print(len(data))\n",
    "\n",
    "# data.dtypes"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2262191\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# d = data.drop_duplicates(subset=['track_uri']) \n",
    "# print(len(d))\n",
    "# d.to_pickle(directory + \"all_track_data.pkl\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2262191\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "tracks = data[['track_uri', \n",
    "       'rock', 'classical', 'classic rock', 'hip hop',\n",
    "       'adult standards', 'rap', 'country rock', 'dance pop', 'mellow gold',\n",
    "       'pop rap', 'gangster rap', 'folk rock', 'soft rock', 'pop',\n",
    "       'album rock', 'alternative rock', 'pop rock', 'soul', 'latin',\n",
    "       'southern hip hop']]\n",
    "len(tracks)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2262191"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "plists = pd.read_csv(directory + 'train_playlists.csv', usecols = ['pid', 'name'], sep='\\t')\n",
    "plists.to_pickle(directory + \"train_playlist_data.pkl\")\n",
    "len(plists)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "interactions = pd.read_pickle(directory+'train_interaction_data.pkl')\n",
    "interactions.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>tid</th>\n",
       "      <th>track_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:0UaMYEvWZi0ZqiDOoHU3YI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:0UaMYEvWZi0ZqiDOoHU3YI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  tid                             track_uri\n",
       "0    0    0  spotify:track:0UaMYEvWZi0ZqiDOoHU3YI\n",
       "1  123    0  spotify:track:0UaMYEvWZi0ZqiDOoHU3YI"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# subset = interactions.iloc[:30000, :].copy() \n",
    "# distinct_tracks = subset['track_uri'].unique()\n",
    "# distinct_playlists = subset['pid'].unique()\n",
    "# tracks = tracks[tracks['track_uri'].isin(distinct_tracks)]\n",
    "# plists = plists[plists['pid'].isin(distinct_playlists)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "distinct_tracks = interactions['track_uri'].unique()\n",
    "distinct_playlists = interactions['pid'].unique()\n",
    "tracks = tracks[tracks['track_uri'].isin(distinct_tracks)]\n",
    "plists = plists[plists['pid'].isin(distinct_playlists)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "t = tracks.drop_duplicates()\n",
    "print(len(distinct_tracks), len(tracks), len(t))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2262190 2262190 2262190\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "graph_builder = PandasGraphBuilder()\n",
    "graph_builder.add_entities(tracks, 'track_uri', 'track')\n",
    "graph_builder.add_entities(plists, 'pid', 'playlist')\n",
    "graph_builder.add_binary_relations(interactions, 'pid', 'track_uri', 'contains')\n",
    "graph_builder.add_binary_relations(interactions, 'track_uri', 'pid', 'contained_by')\n",
    "\n",
    "g = graph_builder.build()\n",
    "g.number_of_nodes('playlist')\n",
    "g.number_of_nodes('track')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2262190"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "genre_columns = tracks.columns.drop(['track_uri'])\n",
    "interactions['present'] = list(1 for i in range(len(interactions)))\n",
    "tracks.columns, plists.columns, genre_columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['track_uri', 'rock', 'classical', 'classic rock', 'hip hop',\n",
       "        'adult standards', 'rap', 'country rock', 'dance pop', 'mellow gold',\n",
       "        'pop rap', 'gangster rap', 'folk rock', 'soft rock', 'pop',\n",
       "        'album rock', 'alternative rock', 'pop rock', 'soul', 'latin',\n",
       "        'southern hip hop'],\n",
       "       dtype='object'),\n",
       " Index(['pid', 'name'], dtype='object'),\n",
       " Index(['rock', 'classical', 'classic rock', 'hip hop', 'adult standards',\n",
       "        'rap', 'country rock', 'dance pop', 'mellow gold', 'pop rap',\n",
       "        'gangster rap', 'folk rock', 'soft rock', 'pop', 'album rock',\n",
       "        'alternative rock', 'pop rock', 'soul', 'latin', 'southern hip hop'],\n",
       "       dtype='object'))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# g.nodes['playlist'].data['name'] = torch.LongTensor(plists['name'])\n",
    "\n",
    "g.nodes['track'].data['genre'] = torch.FloatTensor(tracks[genre_columns].values)\n",
    "\n",
    "g.edges['contains'].data['interaction'] = torch.LongTensor(interactions['present'].values)\n",
    "g.edges['contained_by'].data['interaction'] = torch.LongTensor(interactions['present'].values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def train_test_split_outer(df, user):\n",
    "    df['train_mask'] = np.ones((len(df),), dtype=bool)\n",
    "    df['val_mask'] = np.zeros((len(df),), dtype=bool)\n",
    "    df['test_mask'] = np.zeros((len(df),), dtype=bool)\n",
    "    df = dd.from_pandas(df, npartitions=10)\n",
    "    def train_test_split(df):\n",
    "        if df.shape[0] > 1:\n",
    "            df.iloc[-1, -3] = False\n",
    "            df.iloc[-1, -1] = True\n",
    "        if df.shape[0] > 2:\n",
    "            df.iloc[-2, -3] = False\n",
    "            df.iloc[-2, -2] = True\n",
    "        return df\n",
    "    df = df.groupby(user, group_keys=False).apply(train_test_split).compute(scheduler='processes').sort_index()\n",
    "    return df['train_mask'].to_numpy().nonzero()[0], \\\n",
    "           df['val_mask'].to_numpy().nonzero()[0], \\\n",
    "           df['test_mask'].to_numpy().nonzero()[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "train_indices, val_indices, test_indices = train_test_split_outer(df = interactions, user = 'pid')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-003c50225fd3>:14: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  df = df.groupby(user, group_keys=False).apply(train_test_split).compute(scheduler='processes').sort_index()\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/dask/multiprocessing.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         result = get_async(\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m                 \u001b[0mfire_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/dask/local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3827c8de4f7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split_outer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-003c50225fd3>\u001b[0m in \u001b[0;36mtrain_test_split_outer\u001b[0;34m(df, user)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'processes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m            \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/dask/multiprocessing.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/process.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_management_thread_wakeup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_management_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;31m# objects that use file descriptors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"T: {}, V:{}, T:{}\".format(train_indices, val_indices, test_indices))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_g = build_train_graph(g, train_indices, 'track', 'playlist', 'contains', 'contained_by')\n",
    "assert train_g.out_degrees(etype='watched').min() > 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "output_path = '/Users/rebeccasalganik/Documents/School/2021-2022/Network Science/Capstone/Spotify_Data/baby_dataset.pkl'\n",
    "dataset = {\n",
    "        'train-graph': train_g,\n",
    "        'val-matrix': val_matrix,\n",
    "        'test-matrix': test_matrix,\n",
    "        'item-texts': None,\n",
    "        'item-images': None,\n",
    "        'user-type': 'playlist',\n",
    "        'item-type': 'track',\n",
    "        'user-to-item-type': 'contains',\n",
    "        'item-to-user-type': 'contained_by',\n",
    "        'timestamp-edge-column': 'timestamp'}\n",
    "\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#### BELOW THIS LINE IS OLD CODE "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def load_csv(path): \n",
    "    data = pd.read_csv(path, sep='\\t')\n",
    "    return data \n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "track_p = '/Users/rebeccasalganik/Documents/School/2021-2022/Network Science/Capstone/Spotify_Data/spotify_in_csv/tracks.csv'\n",
    "playlist_p = '/Users/rebeccasalganik/Documents/School/2021-2022/Network Science/Capstone/Spotify_Data/spotify_in_csv/train_playlists.csv'\n",
    "interaction_p = '/Users/rebeccasalganik/Documents/School/2021-2022/Network Science/Capstone/Spotify_Data/spotify_in_csv/train_interactions.csv'\n",
    "\n",
    "tracks = load_csv(track_p)\n",
    "playlists = load_csv(playlist_p)\n",
    "playlists = playlists.rename(columns={\"name\": \"playlist_name\"})\n",
    "interactions = load_csv(interaction_p)\n",
    "print(tracks.columns, playlists.columns, interactions.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['tid', 'arid', 'alid', 'track_uri', 'track_name', 'duration_ms'], dtype='object') Index(['pid', 'playlist_name', 'collaborative', 'modified_at', 'num_albums',\n",
      "       'num_tracks', 'num_followers', 'num_tracks.1', 'num_edits',\n",
      "       'duration_ms', 'num_artists', 'description'],\n",
      "      dtype='object') Index(['pid', 'tid', 'pos'], dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "tracks_all = tracks[['tid', 'arid', 'alid', 'track_uri', 'track_name']]\n",
    "playlists_all = playlists[['pid', 'playlist_name', 'num_albums', 'num_artists', 'num_followers']]\n",
    "interactions_all = interactions[['pid', 'tid']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "baby_t = tracks_all.iloc[:5, :].copy()\n",
    "baby_p = playlists_all.iloc[:5, :].copy()\n",
    "baby_i = interactions_all.iloc[:50, :].copy()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "joined_1 = pd.merge(baby_i, baby_t, how='right', on=[\"tid\"], copy=True)\n",
    "joined_2 = pd.merge(joined_1, baby_p, how=\"inner\", on ='pid', copy=True)\n",
    "joined_2 = joined_2.astype({'pid': 'int', 'tid': 'int'})\n",
    "print(joined_2)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   pid  tid  arid  alid                             track_uri  \\\n",
      "0    0    0     0     0  spotify:track:0UaMYEvWZi0ZqiDOoHU3YI   \n",
      "1    0    1     1     1  spotify:track:6I9VzXrHxO9rA9A5euc8Ak   \n",
      "2    0    2     2     2  spotify:track:0WqIKmW4BTrj3eJFmnCKMv   \n",
      "3    0    3     3     3  spotify:track:1AWQoqb9bSvzTjaLralEkT   \n",
      "4    0    4     4     4  spotify:track:1lzr43nnXAijIGYnCT8M8H   \n",
      "\n",
      "                                   track_name playlist_name  num_albums  \\\n",
      "0  Lose Control (feat. Ciara & Fat Man Scoop)    Throwbacks          47   \n",
      "1                                       Toxic    Throwbacks          47   \n",
      "2                               Crazy In Love    Throwbacks          47   \n",
      "3                              Rock Your Body    Throwbacks          47   \n",
      "4                                It Wasn't Me    Throwbacks          47   \n",
      "\n",
      "   num_artists  num_followers  \n",
      "0           37              1  \n",
      "1           37              1  \n",
      "2           37              1  \n",
      "3           37              1  \n",
      "4           37              1  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "total_set = joined_2[['pid','tid']].copy()\n",
    "track_nodes = baby_t[['tid']].copy()\n",
    "playlist_nodes = baby_p[['pid']].copy()\n",
    "\n",
    "sample_features = [0, 1,2, 3, 4]\n",
    "track_nodes['sample_feats'] = sample_features\n",
    "playlist_nodes['sample_feats'] = sample_features\n",
    "total_set['in'] = [1,1,1,1,1]\n",
    "\n",
    "print(total_set.head())\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   pid  tid  in\n",
      "0    0    0   1\n",
      "1    0    1   1\n",
      "2    0    2   1\n",
      "3    0    3   1\n",
      "4    0    4   1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "distinct_tracks_in_interactions = total_set['tid'].unique()\n",
    "distinct_plists_in_interactions = total_set['pid'].unique()\n",
    "tracks = track_nodes[track_nodes['tid'].isin(distinct_tracks_in_interactions)]\n",
    "plists = playlist_nodes[playlist_nodes['pid'].isin(distinct_plists_in_interactions)]\n",
    "\n",
    "print(tracks.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   tid  sample_feats\n",
      "0    0             0\n",
      "1    1             1\n",
      "2    2             2\n",
      "3    3             3\n",
      "4    4             4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "graph_builder = PandasGraphBuilder()\n",
    "graph_builder.add_entities(tracks, 'tid', 'track')\n",
    "graph_builder.add_entities(plists, 'pid', 'playlist')\n",
    "graph_builder.add_binary_relations(total_set, 'pid', 'tid', 'contains')\n",
    "graph_builder.add_binary_relations(total_set, 'tid', 'pid', 'contained_by')\n",
    "\n",
    "g = graph_builder.build()\n",
    "g.number_of_nodes('playlist')\n",
    "g.number_of_nodes('track')\n",
    "# g.number_of_edges('contained_by') #shouldn't be 5 --> come back "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "g.nodes['track'].data['track_feature'] = torch.LongTensor(tracks['sample_feats'])\n",
    "# g.nodes['track'].data['track_name'] = torch.LongTensor(baby_t['track_name'].cat.codes.values)\n",
    "# g.nodes['track'].data['artist'] = torch.LongTensor(users['age'].cat.codes.values)\n",
    "# g.nodes['track'].data['musical'] = torch.LongTensor(users['occupation'].cat.codes.values)\n",
    "# g.nodes['track'].data['album'] = torch.LongTensor(users['occupation'].cat.codes.values)\n",
    "\n",
    "g.nodes['playlist'].data['playlist_feature'] = torch.LongTensor(plists['sample_feats'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "train_indices, val_indices, test_indices = train_test_split(df = total_set, user = 'pid')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-43-d74d31a762e4>:14: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  df = df.groupby(user, group_keys=False).apply(train_test_split).compute(scheduler='processes').sort_index()\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "print(\"T: {}, V:{}, T:{}\".format(train_indices, val_indices, test_indices))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "T: [0 1 2], V:[3], T:[4]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "def build_train_graph2(g, train_indices, utype, itype, etype, etype_rev):\n",
    "    train_g = g.edge_subgraph(\n",
    "        {etype: train_indices, etype_rev: train_indices},\n",
    "        ) #relabel_nodes=False\n",
    "    for ntype in g.ntypes:\n",
    "        for col, data in g.nodes[ntype].data.items(): \n",
    "            train_g.nodes[ntype].data[col] = data\n",
    "    for etype in g.etypes:\n",
    "        for col, data in g.edges[etype].data.items():\n",
    "            train_g.edges[etype].data[col] = data[train_g.edges[etype].data[dgl.EID]]\n",
    "    print(train_g)\n",
    "    return train_g"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# train_g = build_train_graph(g, train_indices, 'track', 'playlist', 'contains', 'contained_by')\n",
    "train_g = build_train_graph2(g, train_indices, 'track', 'playlist', 'contains', 'contained_by')\n",
    "assert train_g.out_degrees(etype='contains').min() > 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Graph(num_nodes={'playlist': 1, 'track': 3},\n",
      "      num_edges={('playlist', 'contains', 'track'): 3, ('track', 'contained_by', 'playlist'): 3},\n",
      "      metagraph=[('playlist', 'track', 'contains'), ('track', 'playlist', 'contained_by')])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "val_matrix, test_matrix = build_val_test_matrix(g, val_indices, test_indices, 'playlist', 'track', 'contains')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "output_path = '/Users/rebeccasalganik/Documents/School/2021-2022/Network Science/Capstone/Spotify_Data/baby_dataset.pkl'\n",
    "dataset = {\n",
    "        'train-graph': train_g,\n",
    "        'val-matrix': val_matrix,\n",
    "        'test-matrix': test_matrix,\n",
    "#         'item-texts': movie_textual_dataset,\n",
    "        'item-images': None,\n",
    "        'user-type': 'playlist',\n",
    "        'item-type': 'track',\n",
    "        'user-to-item-type': 'contains',\n",
    "        'item-to-user-type': 'contained_by',\n",
    "        'timestamp-edge-column': 'timestamp'}\n",
    "\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9043c765cef53a3739a1c7cc1396456c1b3774c6c5fdef3b660b2990df1a7d93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}